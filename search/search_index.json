{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tracking Artificial Intelligence","text":"<p>Welcome to our website on tracking AI.  We feel that the exponential growth of the capabilities of AI systems in the last 10 years will continue for the foreseeable future.  Many organizations are not tracking the speed that AI systems are improving.  The media is rife with misinformation about what AI can and can't do today and what new capabilities are on the near term horizon (under 10 years).</p> <p>This course helps you understand these trends and helps you put decision frameworks in place to understand why you might want to invest in AI technologies.</p> <p>Please contact me on LinkedIn if you have any specific questions I can help you with.</p>"},{"location":"checklist/","title":"Site Checklist","text":"<ol> <li>Customize the fields in your mkdocs.yml file</li> <li>Configure Google Analytics to use the right site ID</li> <li>Make sure that your .gitignore file includes the <code>site</code> directory</li> <li>Test the build</li> <li>Make sure the Edit button appears</li> <li>Make sure that code color heightening renders correctly</li> <li>run <code>git config advice.addIgnoredFile false</code></li> </ol>"},{"location":"code-highlight-test/","title":"Code Syntax Color Highlight Test","text":""},{"location":"code-highlight-test/#python","title":"Python","text":"<pre><code>hello_string = \"Hello World!\"\nprint(hello_string)\nx = 1\nif x == 1:\n    # indented four spaces\n    print(\"x is 1.\")\n</code></pre>"},{"location":"contact/","title":"Contact","text":"<p>Please contact me on LinkedIn</p> <p>Thanks! - Dan</p>"},{"location":"feedback/","title":"Feedback on Graph Data Modeling","text":"<p>You are welcome to connect with me on anytime on LinkedIn or submit any issues to GitHub Issue Log.  All pull-requests with fixes to errors or additions are always welcome.</p> <p>If you would like to fill out a short survey and give us ideas on how we can create better tools for intelligent textbooks in the future.</p>"},{"location":"glossary/","title":"Glossary of Terms","text":""},{"location":"glossary/#iso-definition","title":"ISO Definition","text":"<p>A term definition is considered to be consistent with ISO metadata registry guideline 11179 if it meets the following criteria:</p> <ol> <li>Precise</li> <li>Concise</li> <li>Distinct</li> <li>Non-circular</li> <li>Unencumbered with business rules</li> </ol>"},{"location":"glossary/#term","title":"Term","text":"<p>This is the definition of the term.</p>"},{"location":"how-we-built-this-site/","title":"How We Built This Site","text":"<p>This page describes how we built this website and some of  the rationale behind why we made various design choices.</p>"},{"location":"how-we-built-this-site/#python","title":"Python","text":"<p>MicroSims are about how we use generative AI to create animations and simulations.  The language of AI is Python.  So we wanted to create a site that could be easily understood by Python developers.</p>"},{"location":"how-we-built-this-site/#mkdocs-vs-docusaurus","title":"Mkdocs vs. Docusaurus","text":"<p>There are two main tools used by Python developers to write documentation: Mkdocs and Docusaurus.  Mkdocs is easier to use and more popular than Docusaurus. Docusaurus is also optimized for single-page applications. Mkdocs also has an extensive library of themes and plugins. None of us are experts in JavaScript or React. Based on our ChatGPT Analysis of the Tradeoffs we chose mkdocs for this site management.</p>"},{"location":"how-we-built-this-site/#github-and-github-pages","title":"GitHub and GitHub Pages","text":"<p>GitHub is a logical choice to store our  site source code and documentation.  GitHub also has a Custom GitHub Action that does auto-deployment if any files on the site change. We don't currently have this action enabled, but other teams can use this feature if they don't have the ability to do a local build with mkdocs.</p> <p>GitHub also has Issues,  Projects and releases that we can use to manage our bugs and tasks.</p> <p>The best practice for low-cost websites that have public-only content is GitHub Pages. Mkdocs has a command (<code>mkdocs gh-deploy</code>) that does deployment directly to GitHub Pages.  This was an easy choice to make.</p>"},{"location":"how-we-built-this-site/#github-clone","title":"GitHub Clone","text":"<p>If you would like to clone this repository, here are the commands:</p> <pre><code>mkdir projects\ncd projects\ngit clone https://github.com/dmccreary/microsims\n</code></pre>"},{"location":"how-we-built-this-site/#after-changes","title":"After Changes","text":"<p>After you make local changes you must do the following:</p> <pre><code># add the new files to a a local commit transaction\ngit add FILES\n# Execute the a local commit with a message about what and why you are doing the commit\ngit commit -m \"comment\"\n# Update the central GitHub repository\ngit push\n</code></pre>"},{"location":"how-we-built-this-site/#material-theme","title":"Material Theme","text":"<p>We had several options when picking a mkdocs theme:</p> <ol> <li>Mkdocs default</li> <li>Readthedocs</li> <li>Third-Party Themes See Ranking</li> </ol> <p>The Material Theme had 16K stars.  No other theme had over a few hundred. This was also an easy design decision.</p> <p>One key criterial was the social Open Graph tags so that when our users post a link to a simulation, the image of the simulation is included in the link.  Since Material supported this, we used the Material theme. You can see our ChatGPT Design Decision Analysis if you want to check our decision process.</p>"},{"location":"how-we-built-this-site/#enable-edit-icon","title":"Enable Edit Icon","text":"<p>To enable the Edit icon on all pages, you must add the edit_uri and the content.action.edit under the theme features area.</p> <pre><code>edit_uri: edit/master/docs/\n</code></pre> <pre><code>    theme:\n        features:\n            - content.action.edit\n</code></pre>"},{"location":"how-we-built-this-site/#conda-vs-venv","title":"Conda vs VENV","text":"<p>There are two choices for virtual environments.  We can use the native Python venv or use Conda.  venv is simle but is only designed for pure Python projects.  We imagine that this site could use JavaScript and other langauges in the future, so we picked Conda. There is nothing on this microsite that prevents you from using one or the other.  See the ChatGPT Analysis Here.</p> <p>Here is the conda script that we ran to create a new mkdocs environment that also supports the material social imaging libraries.</p> <pre><code>conda deactivate\nconda create -n mkdocs python=3\nconda activate mkdocs\npip install mkdocs \"mkdocs-material[imaging]\"\n</code></pre>"},{"location":"how-we-built-this-site/#mkdocs-commands","title":"Mkdocs Commands","text":"<p>There are three simple mkdoc commands we use.</p>"},{"location":"how-we-built-this-site/#local-build","title":"Local Build","text":"<pre><code>mkdocs build\n</code></pre> <p>This builds your website in a folder called <code>site</code>.  Use this to test that the mkdocs.yml site is working and does not have any errors.</p>"},{"location":"how-we-built-this-site/#run-a-local-server","title":"Run a Local Server","text":"<pre><code>mkdocs serve\n</code></pre> <p>This runs a server on <code>http://localhost:8000</code>. Use this to test the display formatting locally before you push your code up to the GitHub repo.</p> <pre><code>mkdoc gh-deploy\n</code></pre> <p>This pushes everything up to the GitHub Pages site. Note that it does not commit your code to GitHub.</p>"},{"location":"how-we-built-this-site/#mkdocs-material-social-tags","title":"Mkdocs Material Social Tags","text":"<p>We are using the Material Social tags.  This is a work in progress!</p> <p>Here is what we have learned.</p> <ol> <li>There are extensive image processing libraries that can't be installed with just pip.  You will need to run a tool like brew on the Mac to get the libraries installed.</li> <li>Even after <code>brew</code> installs the libraries, you have to get your environment to find the libraries.  The only way I could get that to work was to set up a local UNIX environment variable.</li> </ol> <p>Here is the brew command that I ran:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>I then had to add the following to my ~/.zshrc file:</p> <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\n</code></pre> <p>Note that I am running on a Mac with Apple silicon.  This means that the image libraries that brew downloads must be specific to the Mac Arm instruction set.</p>"},{"location":"how-we-built-this-site/#image-generation-and-compression","title":"Image Generation and Compression","text":"<p>I have used ChatGPT to create most of my images.  However, they are too large for most websites.  To compress them down I used  https://tinypng.com/ which is a free tool  for compressing png images without significant loss of quality.  The files created with ChatGPT are typically around 1-2 MB.  After  using the TinyPNG site the size is typically around 200-300KB.</p> <ul> <li>Cover images for blog post #4364</li> <li>Discussion on overriding the Social Card Image</li> </ul>"},{"location":"license/","title":"Creative Commons License","text":"<p>All content in this repository is governed by the following license agreement:</p>"},{"location":"license/#license-type","title":"License Type","text":"<p>Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED)</p>"},{"location":"license/#link-to-license-agreement","title":"Link to License Agreement","text":"<p>https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en</p>"},{"location":"license/#your-rights","title":"Your Rights","text":"<p>You are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format</li> <li>Adapt \u2014 remix, transform, and build upon the material</li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p>"},{"location":"license/#restrictions","title":"Restrictions","text":"<ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> <li>No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</li> </ul> <p>Notices</p> <p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.</p> <p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.</p> <p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>"},{"location":"references/","title":"References","text":"<p>Powerful A.I. Is Coming. We\u2019re Not Ready. - New York Times - March 14, 2025 - By Kevin Roose - Three arguments for taking progress toward artificial general intelligence, or A.G.I., more seriously \u2014 whether you\u2019re an optimist or a pessimist.</p> <p>Site References</p> <ol> <li>mkdocs - https://www.mkdocs.org/ - this is our tool for building the website.  It converts Markdown into HTML in the <code>site</code> directory.</li> <li>mkdocs material theme - https://squidfunk.github.io/mkdocs-material/ - this is the theme for our site.  The theme adds the user interface elements that give our site the look and feel.  It also has the features such as social cards.</li> <li>GitHub Pages - https://pages.github.com/ - this is the free tool for hosting public websites created by mkdocs</li> <li>Markdown - https://www.mkdocs.org/user-guide/writing-your-docs/#writing-with-markdown - this is the format we use for text.  It allows us to have headers, lists, tables, links and images without learning HTML.</li> <li>Deploy Mkdocs GitHub Action - https://github.com/marketplace/actions/deploy-mkdocs - this is the tool we use to automatically build our site after edits are checked in with Git.</li> <li>Git Book - https://git-scm.com/book/en/v2 - a useful book on Git.  Just read the first two chapters to learn how to check in new code.</li> <li>Conda - https://conda.io/ - this is a command line tool that keeps our Python libraries organized for each project.</li> <li>VS Code - https://code.visualstudio.com/ - this is the integrated development environment we use to mange the files on our website.</li> <li>Markdown Paste - https://marketplace.visualstudio.com/items?itemName=telesoho.vscode-markdown-paste-image - this is the VS code extension we use to make sure we keep the markdown format generated by ChatGPT.</li> </ol>"},{"location":"chapters/current-state/","title":"Current State","text":""},{"location":"chapters/skepticism-of-the-llm-only-path/","title":"Skepticism of the LLM Only Path","text":"<p>On March 4th, 2025 Nature published an article by Nicola Jones that surveyed AI researchers on our progress toward achieving Artificial General Intelligence (AGI).  Here is a summary of some points this article says about the limitations of current LLMs.</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#summary-of-llm-limitations-according-to-the-nature-article","title":"Summary of LLM Limitations According to the Nature Article","text":"<p>The Nature article by Nicola Jones, published on March 4, 2025, reports on a survey conducted by the Association for the Advancement of Artificial Intelligence (AAAI) among AI researchers. Here are the key findings about the limitations of current LLMs:</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#fundamental-architectural-limitations","title":"Fundamental Architectural Limitations","text":"<p>The survey reveals that most respondents are skeptical that the technology underpinning large-language models is sufficient for artificial general intelligence. Specifically:</p> <p>84% of AI professionals believe that relying solely on neural networks is insufficient for achieving AGI. The researchers don't believe that simply scaling up neural networks will bridge the gap to human-level intelligence.</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#scaling-is-not-the-solution","title":"Scaling is Not the Solution","text":"<p>Over 75% believe that merely scaling up existing AI systems won't suffice. The survey reveals that the vast majority of AI researchers doubt that continuing to make neural networks bigger and training them on more data - the approach that has driven recent AI advances - will lead to AGI.</p> <p>an overwhelming 76 percent of respondents said it was \"unlikely\" or \"very unlikely\" to succeed when asked about whether scaling up current AI approaches could lead to achieving AGI.</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#need-for-hybrid-approaches","title":"Need for Hybrid Approaches","text":"<p>a majority advocate for incorporating symbolic AI techniques and more than 60% of those surveyed support the idea that human-level reasoning requires a blend of neural network-based systems and symbolic AI.</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#specific-architectural-limitations","title":"Specific Architectural Limitations","text":"<p>The article, as reported by various sources, indicates that current LLMs lack: - True understanding of concepts (they recognize statistical patterns but don't grasp meaning) - Inherent logical reasoning capabilities - Consistent and reliable decision-making abilities - The ability to structure explicit logic and reasoning</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#priority-shift","title":"Priority Shift","text":"<p>Interestingly, 75% prioritize developing AI with a favorable risk-benefit profile over pursuing AGI, suggesting a shift in research priorities from pure pursuit of AGI to more practical and beneficial AI development.</p> <p>The article paints a picture of the AI research community questioning the fundamental approach that has dominated recent AI development and calling for a fundamental shift in methodology to achieve true artificial general intelligence.</p> <p>The Nature article titled \u201cHow AI can achieve human-level intelligence: researchers call for change in tack\u201d by Nicola Jones, published on March 4, 2025, highlights several limitations of current large language models (LLMs) in achieving artificial general intelligence (AGI).</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#key-limitations-of-current-llms","title":"Key Limitations of Current LLMs","text":"<ol> <li> <p>Lack of True Reasoning and Planning: LLMs excel at generating human-like text but struggle with tasks requiring genuine reasoning and long-term planning. Their outputs are often based on pattern recognition rather than understanding, limiting their ability to perform complex cognitive tasks.</p> </li> <li> <p>Absence of Common Sense and World Modeling: These models lack an inherent understanding of the physical world and common sense reasoning. Without the ability to model real-world scenarios, their applicability in dynamic and unpredictable environments is constrained.</p> </li> <li> <p>Inadequate Internal Deliberation: Unlike humans, LLMs do not possess internal deliberative processes. This deficiency hampers their capacity to evaluate information critically and make informed decisions, which are essential components of human-like intelligence.</p> </li> <li> <p>Overreliance on Data Scaling: The current trajectory of enhancing LLMs primarily involves increasing data and computational resources. However, this approach yields diminishing returns concerning the development of AGI, as it doesn't address foundational cognitive limitations.</p> </li> </ol>"},{"location":"chapters/skepticism-of-the-llm-only-path/#calls-for-a-paradigm-shift","title":"Calls for a Paradigm Shift","text":"<p>The article emphasizes that to progress toward AGI, researchers advocate for a shift from merely scaling existing models to developing new architectures that incorporate elements like symbolic reasoning, embodied cognition, and neural-symbolic integration. Such approaches aim to imbue AI systems with a more profound understanding and flexible problem-solving abilities akin to human intelligence.</p> <p>This perspective aligns with views from AI experts like Yann LeCun, who argue that LLMs, in their current form, are insufficient for achieving human-level intelligence and that alternative methodologies are necessary for meaningful advancement in the field. ([Financial Times][1])</p> <p>In summary, while LLMs have made significant strides in natural language processing, their inherent limitations necessitate a reevaluation of strategies to achieve true artificial general intelligence.</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#references","title":"References","text":"<ul> <li> <p>Meta AI chief says large language models will not reach human intelligence</p> </li> <li> <p>How AI can achieve human-level intelligence: researchers call for change in tack - Nature - March 4th, 2025 - By Nicola Jones A survey finds that most respondents are skeptical that the technology underpinning large-language models is sufficient for artificial general intelligence.</p> </li> <li> <p>Will AI ever reach human-level intelligence? We asked 5 experts Padlokr</p> </li> <li> <p>Bing Search</p> </li> </ul>"},{"location":"stories/","title":"Tracking AI","text":""},{"location":"stories/#yann-lecun","title":"Yann LeCun","text":"<p>This story chronicles Yann LeCun's journey from a curious teenager in 1970s Paris to a pioneering AI researcher who revolutionized machine learning. It follows his development of convolutional neural networks (CNNs) at AT&amp;T Bell Labs for optical character recognition, his forward-thinking establishment of the NYU Center for Data Science in 2012, and his collaboration in founding ICLR to unite the field. The narrative culminates with his 2019 Turing Award and explores his thoughtful skepticism about achieving AGI through large language models alone, emphasizing his belief that future AI systems need comprehensive world models to achieve true intelligence. Throughout, the story illustrates how LeCun combined deep technical innovation with visionary leadership to challenge the status quo and transform what was possible in artificial intelligence.</p> <p>Read the Yann LeCun Story</p>"},{"location":"stories/yann-lecun/","title":"The Visionary who Saw the Future: Yann LeCun's Quest for Intelligent Machines","text":"Show Image Prompt Cover Image: Create a vibrant, tech-optimistic wide-landscape graphic novel cover featuring Yann LeCun as the central figure, depicted in a heroic pose with his arms outstretched toward twin horizons representing past and future. The left horizon shows early computing (1970s-1980s) with vintage computers, handwritten digits, and primitive neural network diagrams, rendered in warm sepia tones. The right horizon explodes with modern AI technology - glowing neural networks, holographic data streams, and interconnected global nodes, rendered in brilliant cyans, magentas, and electric blues.  Behind LeCun, create a dramatic split background where the upper half shows the physical world with realistic buildings, labs, and libraries, while the lower half reveals the digital realm of mathematical concepts materialized as floating equations, converging networks, and architectural visualizations of CNNs. These two realms should blend seamlessly through LeCun's silhouette, with light streaming from his head and heart to represent the flow of ideas.  Above the scene, incorporate three distinct layers: the bottom layer shows early perceptrons and simple neural networks, the middle layer displays complex CNN architectures, and the top layer hints at future world models with intricate cause-and-effect relationships. Use flowing energy lines and glowing nodes to connect these layers, suggesting evolution and continuity. The title 'THE VISIONARY WHO SAW THE FUTURE: YANN LECUN'S QUEST FOR INTELLIGENT MACHINES' should be integrated organically into the design, perhaps formed by neural pathways or data streams. Use a bold, modern typeface that complements the tech-forward aesthetic.  The overall color palette should be bright and optimistic, featuring deep blues for computational elements, warm golds for human insight and eureka moments, vibrant greens for growth and innovation, and luminous whites for breakthrough moments. The style should blend technical accuracy with artistic interpretation, making complex AI concepts visually accessible and inspiring.  Include subtle Easter eggs like the iconic handwritten '5' and '7' digits from his early work, equations floating in the background, and miniature depictions of key moments from his career. The composition should draw the reader's eye in a circular motion, starting from LeCun's determined expression, sweeping through the technological landscape, and returning to his visionary gaze toward the future.  The entire image must be rendered in a wide-landscape format suitable for a graphic novel cover, with dramatic lighting that emphasizes the contrast between challenges overcome and possibilities ahead.  Show Narrative Prompt Please create a detailed fun and entertaining story for high-school students about the AI researcher Yann LeCun.  Generate a narrative text but also create detailed descriptions of graph-novel panels that can be inserted into the story at appropriate places.  The theme of the story is how LeCun challenged the status quo and has overcome obstacles in his career by combining both a deep technical understanding and leadership skills.  Tell how in 1988, LeCun joined the Adaptive Systems Research Department at AT&amp;T Bell Laboratories in Holmdel, New Jersey and worked on machine learning.  Give a detailed background of how his career started doing optical character recognition and computer vision using convolutional neural networks (CNNs).  Tell how in 2012, he became the founding director of the NYU Center for Data Science, before the term \"Data Science\" was popular.  Tell how it 2013, he and Yoshua Bengio co-founded the International Conference on Learning Representations to promote good research in the field of machine learning.  Tell how in March 2019, LeCun won the 2018 Turing Award, sharing it with Yoshua Bengio and Geoffrey Hinton.  Tell how LeCun is extremely skeptical that LLMs alone will ever achieve levels of artificial general intelligence (AGI).  Discuss how LeCun feels that precise world models must be used to achieve AGI.  Our goal is to have you generate the full text of the story, but to turn the story into a graphic novel with many illustrations that explains the arc of  LeCun career.   When appropriate, suggest an image that could be inserted into the story to make the story a graphic novel.   Describe each image in detail and be consistent across all the images in the story for style. When you describe an image, make sure to mention that it should be a colorful, bright wide-landscape drawing suitable for technology-forward optimistic graphic-novel."},{"location":"stories/yann-lecun/#prologue-the-dreamer","title":"Prologue: The Dreamer","text":"Show Image Prompt Image 1: A colorful, bright wide-landscape drawing showing a young Yann LeCun as a teenager in France, sitting in a library surrounded by dusty books on mathematics and computing. The scene should be split between the physical reality showing him studying analog electronics and computing manuals, and a dreamy overlay showing his imagination of neural networks as glowing interconnected nodes floating above his head. The style should be vibrant and optimistic, with warm lighting streaming through library windows.  <p>In the early 1970s, while most teenagers dreamed of rock concerts and fast cars, young Yann LeCun spent his evenings in the local library in suburban Paris, devouring books on mathematics, computer science, and the emerging field of artificial intelligence. His friends thought he was eccentric \u2013 who dreams of teaching machines to think? But Yann's vision was clear: machines could learn like humans do, through observation and experience.</p>"},{"location":"stories/yann-lecun/#chapter-1-bell-labs-the-spark-of-innovation","title":"Chapter 1: Bell Labs: The Spark of Innovation","text":"Show Image Prompt Please create a new version of [this image](./holmdell-1980.jpeg) using a drawing that might appear in a colorful bright graphic novel.   <p>In 1988, LeCun joined the legendary AT&amp;T Bell Laboratories in Holmdel New Jersey were over 6,000 engineers and researchers did some of the most groundbreaking research in computer science.</p> <p></p> Show Image Prompt Image 2: Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A tech-optimistic graphic novel panel showing LeCun as a young researcher at AT&amp;T Bell Labs in 1988, working late at night surrounded by early computers and neural network diagrams on whiteboards. The scene should depict him animated and excited, gesturing toward holographic representations of digits floating above a primitive neural network diagram. The setting should have the warm orange glow of desk lamps and the blue light of computer monitors, creating an atmosphere of discovery.  <p>Holmdel was a place where innovation flowed like electricity through the halls. While others worked on traditional software, LeCun's office became a laboratory of the future. His colleagues often found him staring intently at a screen filled with handwritten digits, muttering about \"convolutional filters\" and \"local receptive fields.\" </p> <p>\"Why are you trying to reinvent image recognition?\" his skeptical colleagues would ask. \"Rule-based systems work just fine for reading zip codes.\"</p> <p>But LeCun had a vision that others couldn't yet see.</p>"},{"location":"stories/yann-lecun/#chapter-2-the-convolutional-revolution","title":"Chapter 2: The Convolutional Revolution","text":"Show Image Prompt Image 3:  Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A dynamic wide-landscape illustration showing the inner workings of a CNN processing handwritten digits. The scene should be depicted as an ethereal journey through multiple layers of convolution, showing the transition from raw pixels to abstract features. Use flowing, interconnected neural pathways with bright colors \u2013 blues for initial features, transitioning to greens for edges, yellows for shapes, and reds for final classification. The style should be both technical and artistic, making neural network concepts visually beautiful.  <p>Working late into countless nights, LeCun developed something revolutionary: convolutional neural networks (CNNs). While traditional neural networks struggled with images, treating each pixel independently, LeCun's CNNs understood that images had structure \u2013 edges, corners, shapes that mattered.</p> <p>His breakthrough came when his CNN successfully read handwritten digits on checks. The system learned to recognize numbers the way humans do \u2013 by understanding patterns and structures, not by memorizing every possible variation. AT&amp;T saved millions of dollars with this technology, but LeCun knew this was just the beginning.</p> <p></p> Show Image Prompt Image 4:  Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.   A triumphant scene in a bank processing center, split between the mundane reality of workers manually sorting checks and the futuristic overlay of LeCun's CNN system automatically reading and processing thousands of checks with glowing accuracy indicators. The style should contrast the gray, tedious manual work with the vibrant, efficient automated system powered by neural networks."},{"location":"stories/yann-lecun/#chapter-3-the-data-science-pioneer","title":"Chapter 3: The Data Science Pioneer","text":"Show Image Prompt Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.   Image 5: A colorful wide-landscape showing the inauguration of the NYU Center for Data Science in 2012. The scene should depict LeCun on stage, but instead of a traditional podium, he's surrounded by floating holographic data visualizations, neural networks, and equations. In the audience, show a mix of excited students and skeptical faculty members, with some thinking \"Data Science? That's not a real field!\" The setting should feel like a tech startup meets academic institution, with modern architecture and vibrant colors.  <p>By 2012, LeCun was ready for his next challenge. When offered a position at NYU, he didn't just join \u2013 he created something entirely new: the Center for Data Science. Many academics scoffed. \"Data Science? That's just statistics with a fancy name!\"</p> <p>But LeCun saw the future clearly. Data was becoming the world's most valuable resource, and the techniques he'd been developing could unlock its secrets. Under his leadership, the center became a magnet for brilliant minds from computer science, statistics, and engineering. Together, they pioneered the field that would soon take the world by storm.</p>"},{"location":"stories/yann-lecun/#chapter-4-building-bridges","title":"Chapter 4: Building Bridges","text":"Show Image Prompt Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.   Image 6: A conference room scene showing the first International Conference on Learning Representations (ICLR) in 2013. The panel should show LeCun and Yoshua Bengio planting seeds that grow into a massive tree of knowledge, with branches reaching out to connect researchers worldwide. Each connection should be represented by glowing lines forming a global network of innovation. The style should be aspirational and forward-thinking, with a global map in the background showing research nodes lighting up across continents.  <p>In 2013, LeCun and his longtime collaborator Yoshua Bengio faced another challenge: the field of machine learning was fragmented, with researchers working in isolation. They founded the International Conference on Learning Representations (ICLR), creating a space where ideas could flow freely.</p> <p>\"We need to build bridges, not walls,\" LeCun declared at the first conference. His vision was simple but powerful: share knowledge openly, challenge each other's ideas, and accelerate progress for everyone.</p>"},{"location":"stories/yann-lecun/#chapter-5-the-turing-triumph","title":"Chapter 5: The Turing Triumph","text":"Show Image Prompt Image 7: Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A spectacular wide-landscape showing the 2019 Turing Award ceremony with LeCun, Bengio, and Hinton standing together. Instead of just receiving medals, they should be depicted as knights of the digital realm, with data streams and neural networks forming crowns above their heads. The scene should be celebratory with confetti, but also symbolic \u2013 showing how their work has literally reshaped the world, with elements of their innovations (CNNs, deep learning, AI applications) transforming the environment around them.  <p>March 2019 brought the ultimate recognition: the Turing Award, computing's highest honor. LeCun shared this prestigious award with Yoshua Bengio and Geoffrey Hinton \u2013 three pioneers who had persevered through decades of skepticism to revolutionize artificial intelligence.</p> <p>At the ceremony, LeCun spoke not just about past achievements, but about future challenges. \"This is not the end,\" he declared. \"This is just the beginning of our understanding of intelligence.\"</p>"},{"location":"stories/yann-lecun/#chapter-6-the-agi-skeptic","title":"Chapter 6: The AGI Skeptic","text":"Show Image Prompt Image 8: Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.   A thought-provoking wide-landscape showing LeCun in his office, surrounded by whiteboards filled with diagrams. On one side, show simplified representations of LLMs (depicted as pattern-matching machines), and on the other side, show his vision of world models as complex, interconnected systems. The scene should include holographic projections of physical simulations, cause-and-effect relationships, and reasoning engines. The contrast should be clear but non-judgmental, emphasizing the complementary nature of different AI approaches.  <p>While the world celebrated the rise of large language models (LLMs) like ChatGPT, LeCun remained thoughtfully skeptical. \"Language models are impressive, but they're not enough for true intelligence,\" he would explain to packed auditoriums.</p> <p>His vision went deeper: machines needed to understand the world, not just predict text. They needed world models \u2013 internal representations of how things work, what causes what, and how to reason about unseen situations. This wasn't criticism for its own sake; this was the perspective of someone who had seen the field evolve and knew there were greater heights to reach.</p> <p></p> Show Image Prompt Image 9:  Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A visionary scene showing LeCun's concept of future AI systems. The panel should illustrate a split reality: above, current AI systems performing specific tasks (language, image recognition, etc.), and below, an integrated AI system with a comprehensive world model. This lower level should be depicted as a sophisticated machine understanding the physical world, social dynamics, causal relationships, and abstract reasoning \u2013 all connected in a harmonious, glowing network of understanding.  <p> Yann's vision is an AI system that mimics regions of the human brain.  At the center of this is models of the real world.  LLMs are good models of language, but they are not precise models of the world.</p>"},{"location":"stories/yann-lecun/#epilogue-the-continuing-quest","title":"Epilogue: The Continuing Quest","text":"Show Image Prompt Image 10:  Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A forward-looking wide-landscape that serves as the story's finale. Show LeCun as an elder statesman of AI, but still actively working and mentoring young researchers. The scene should be set in a futuristic lab where his influence is visible everywhere \u2013 from CNNs processing visual data to young scientists working on world models and next-generation AI. The atmosphere should be optimistic and inclusive, showing a diverse group of researchers continuing his legacy of challenging assumptions and pushing boundaries.  <p>Today, Yann LeCun continues his quest for truly intelligent machines. His journey from a curious teenager in Paris to a pioneering force in artificial intelligence shows that the greatest obstacles to progress are often our own preconceptions. By combining deep technical understanding with visionary leadership, he didn't just overcome challenges \u2013 he redefined what was possible.</p> <p>As he likes to say, \"The best way to predict the future is to create it.\" And for Yann LeCun, the future of artificial intelligence is still being written.</p> <p></p> Show Image Prompt Image 11:  Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A symbolic closing panel showing hands passing a torch between generations of AI researchers. In the background, the evolution of neural networks can be seen as a spiral timeline, from simple perceptrons to modern CNNs to future world models. The torch itself should be rendered as a glowing neural network, symbolizing the continuous flow of knowledge and innovation. The style should be hopeful and inspiring, suggesting that the story continues with each new generation of researchers."},{"location":"stories/yann-lecun/#references","title":"References","text":"<p>Here are the references reformatted:</p> <ol> <li>Yann LeCun Personal Website</li> <li>Gradient-based learning applied to document recognition - 1998 - Proceedings of the IEEE - LeCun's seminal CNN paper describing implementation at AT&amp;T Bell Labs</li> <li>MNIST Database of Handwritten Digits - 2010 (Updated) - Online Database - Original dataset created from Bell Labs work on postal code recognition</li> <li>Handwritten Digit Recognition with a Back-Propagation Network - 1990 - Advances in Neural Information Processing Systems - Early AT&amp;T Bell Labs application work</li> <li>ACM Turing Award Winners - 2019 - ACM Official Page - Official announcement of 2018 Turing Award to LeCun, Bengio, and Hinton</li> <li>NYU Center for Data Science Launch - 2012 - NYU Official Page - Founding of center with LeCun as inaugural director</li> <li>ICLR Conference History - 2013 - ICLR Official Website - Co-founded by LeCun and Bengio as premier ML conference</li> <li>LeCun's NYU Profile - Current - NYU CS Department - Official position at NYU and CV</li> <li>LeCun on AI and World Models - 2022 - MIT Technology Review - Recent interview on LLM limitations and AGI</li> <li>Facebook AI Research Appointment - 2013 - Meta Research Blog - Announcement of LeCun as FAIR director at Meta</li> <li>LeCun at Bell Labs Research - 1988-2003 - Bell Labs Archives - Documentation of LeCun's tenure and achievements at AT&amp;T Bell Labs</li> </ol>"}]}