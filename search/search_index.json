{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Tracking Artificial Intelligence","text":"<p>Welcome to our website on tracking AI.  We feel that the exponential growth of the capabilities of AI systems in the last 10 years will continue for the foreseeable future.  Many organizations are not tracking the speed that AI systems are improving.  The media is rife with misinformation about what AI can and can't do today and what new capabilities are on the near term horizon (under 10 years).</p> <p>This course helps you understand these trends and helps you put decision frameworks in place to understand why you might want to invest in AI technologies.</p> <p>Please contact me on LinkedIn if you have any specific questions I can help you with.</p>"},{"location":"checklist/","title":"Site Checklist","text":"<ol> <li>Customize the fields in your mkdocs.yml file</li> <li>Configure Google Analytics to use the right site ID</li> <li>Make sure that your .gitignore file includes the <code>site</code> directory</li> <li>Test the build</li> <li>Make sure the Edit button appears</li> <li>Make sure that code color heightening renders correctly</li> <li>run <code>git config advice.addIgnoredFile false</code></li> </ol>"},{"location":"contact/","title":"Contact","text":"<p>Please contact me on LinkedIn</p> <p>Thanks! - Dan</p>"},{"location":"course-description/","title":"Tracking AI - Course Description","text":"<p>Prompt</p> <p>Help me write a course description for a three-day course on understanding the exponential growth rate of AI and the strategic implications on organizations such as schools, colleges and universities as well as other businesses.  Focus on how high-quality content generation is allowing almost anyone to generate text and images.  Describe how most organizations that manage knowledge will be impacted.  Include content that tracks AI capabilities such as AI benchmarks and question answering.  Discuss the limitations of current LLMs and their lack of world models.  Discuss how organizations are building generative AI centers of excellence to review ideas on how organizations can use AI to be more productive.</p>"},{"location":"course-description/#exponential-ai-strategic-implications-for-knowledge-organizations","title":"Exponential AI: Strategic Implications for Knowledge Organizations","text":""},{"location":"course-description/#course-description","title":"Course Description","text":"<p>This three-day intensive course explores the exponential growth of artificial intelligence and its profound strategic implications for knowledge-based organizations including educational institutions and businesses. Participants will gain a comprehensive understanding of how generative AI is transforming content creation, knowledge management, and organizational productivity.</p>"},{"location":"course-description/#day-1-understanding-ais-exponential-growth","title":"Day 1: Understanding AI's Exponential Growth","text":""},{"location":"course-description/#morning-foundations-of-ai-growth","title":"Morning: Foundations of AI Growth","text":"<ul> <li>AI capability trajectories: Historical perspective and acceleration patterns</li> <li>Key AI benchmarks: From ImageNet to modern benchmarks like MMLU and HumanEval</li> <li>Defining exponential growth in the context of AI development</li> <li>Case studies of breakthrough moments in AI development</li> </ul>"},{"location":"course-description/#afternoon-content-generation-revolution","title":"Afternoon: Content Generation Revolution","text":"<ul> <li>Text generation capabilities: From basic templates to human-level writing</li> <li>Image generation evolution: DALL-E to Midjourney and beyond</li> <li>Democratization of content creation tools</li> <li>Hands-on workshop: Experiencing various content generation platforms</li> </ul>"},{"location":"course-description/#day-2-organizational-impact-assessment","title":"Day 2: Organizational Impact Assessment","text":""},{"location":"course-description/#morning-educational-institution-impacts","title":"Morning: Educational Institution Impacts","text":"<ul> <li>Transforming teaching methodologies and curriculum development</li> <li>Assessment challenges in an AI-assisted world</li> <li>Research integrity and academic publishing considerations</li> <li>Student skill development for an AI-augmented future</li> </ul>"},{"location":"course-description/#afternoon-business-transformation","title":"Afternoon: Business Transformation","text":"<ul> <li>Knowledge worker productivity shifts</li> <li>Customer service and engagement transformations</li> <li>Product development acceleration</li> <li>Strategic competitive advantages through AI adoption</li> <li>Workshop: Impact assessment for your organization</li> </ul>"},{"location":"course-description/#day-3-strategic-response-planning","title":"Day 3: Strategic Response Planning","text":""},{"location":"course-description/#morning-limitations-and-realistic-expectations","title":"Morning: Limitations and Realistic Expectations","text":"<ul> <li>Current limitations of large language models</li> <li>Understanding the absence of world models in current AI</li> <li>Hallucination challenges and factual reliability</li> <li>Ethical considerations and responsible AI deployment</li> </ul>"},{"location":"course-description/#afternoon-building-ai-centers-of-excellence","title":"Afternoon: Building AI Centers of Excellence","text":"<ul> <li>Organizational structures for AI integration</li> <li>Developing AI literacy across all organizational levels</li> <li>Creating governance frameworks for responsible AI use</li> <li>Implementation roadmapping and change management</li> <li>Workshop: Drafting your organization's AI strategy</li> </ul>"},{"location":"course-description/#learning-outcomes","title":"Learning Outcomes","text":"<p>By completing this course, participants will: - Understand the exponential growth patterns of AI capabilities and their strategic implications - Identify specific areas where AI will transform their organization's operations - Recognize both the potentials and limitations of current AI technologies - Develop frameworks for establishing AI centers of excellence - Create preliminary strategic plans for AI integration in their organizations</p>"},{"location":"course-description/#who-should-attend","title":"Who Should Attend","text":"<ul> <li>Educational leaders and administrators</li> <li>Business executives and strategic planners</li> <li>Knowledge management professionals</li> <li>Innovation and digital transformation leaders</li> <li>Department heads responsible for organizational productivity</li> </ul> <p>Limited to 30 participants to ensure interactive learning and personalized strategic planning assistance.</p>"},{"location":"feedback/","title":"Feedback on Graph Data Modeling","text":"<p>You are welcome to connect with me on anytime on LinkedIn or submit any issues to GitHub Issue Log.  All pull-requests with fixes to errors or additions are always welcome.</p> <p>If you would like to fill out a short survey and give us ideas on how we can create better tools for intelligent textbooks in the future.</p>"},{"location":"glossary/","title":"Glossary of Terms","text":""},{"location":"glossary/#iso-definition","title":"ISO Definition","text":"<p>A term definition is considered to be consistent with ISO metadata registry guideline 11179 if it meets the following criteria:</p> <ol> <li>Precise</li> <li>Concise</li> <li>Distinct</li> <li>Non-circular</li> <li>Unencumbered with business rules</li> </ol>"},{"location":"glossary/#term","title":"Term","text":"<p>This is the definition of the term.</p>"},{"location":"how-we-built-this-site/","title":"How We Built This Site","text":"<p>This page describes how we built this website and some of  the rationale behind why we made various design choices.</p>"},{"location":"how-we-built-this-site/#python","title":"Python","text":"<p>MicroSims are about how we use generative AI to create animations and simulations.  The language of AI is Python.  So we wanted to create a site that could be easily understood by Python developers.</p>"},{"location":"how-we-built-this-site/#mkdocs-vs-docusaurus","title":"Mkdocs vs. Docusaurus","text":"<p>There are two main tools used by Python developers to write documentation: Mkdocs and Docusaurus.  Mkdocs is easier to use and more popular than Docusaurus. Docusaurus is also optimized for single-page applications. Mkdocs also has an extensive library of themes and plugins. None of us are experts in JavaScript or React. Based on our ChatGPT Analysis of the Tradeoffs we chose mkdocs for this site management.</p>"},{"location":"how-we-built-this-site/#github-and-github-pages","title":"GitHub and GitHub Pages","text":"<p>GitHub is a logical choice to store our  site source code and documentation.  GitHub also has a Custom GitHub Action that does auto-deployment if any files on the site change. We don't currently have this action enabled, but other teams can use this feature if they don't have the ability to do a local build with mkdocs.</p> <p>GitHub also has Issues,  Projects and releases that we can use to manage our bugs and tasks.</p> <p>The best practice for low-cost websites that have public-only content is GitHub Pages. Mkdocs has a command (<code>mkdocs gh-deploy</code>) that does deployment directly to GitHub Pages.  This was an easy choice to make.</p>"},{"location":"how-we-built-this-site/#github-clone","title":"GitHub Clone","text":"<p>If you would like to clone this repository, here are the commands:</p> <pre><code>mkdir projects\ncd projects\ngit clone https://github.com/dmccreary/microsims\n</code></pre>"},{"location":"how-we-built-this-site/#after-changes","title":"After Changes","text":"<p>After you make local changes you must do the following:</p> <pre><code># add the new files to a a local commit transaction\ngit add FILES\n# Execute the a local commit with a message about what and why you are doing the commit\ngit commit -m \"comment\"\n# Update the central GitHub repository\ngit push\n</code></pre>"},{"location":"how-we-built-this-site/#material-theme","title":"Material Theme","text":"<p>We had several options when picking a mkdocs theme:</p> <ol> <li>Mkdocs default</li> <li>Readthedocs</li> <li>Third-Party Themes See Ranking</li> </ol> <p>The Material Theme had 16K stars.  No other theme had over a few hundred. This was also an easy design decision.</p> <p>One key criterial was the social Open Graph tags so that when our users post a link to a simulation, the image of the simulation is included in the link.  Since Material supported this, we used the Material theme. You can see our ChatGPT Design Decision Analysis if you want to check our decision process.</p>"},{"location":"how-we-built-this-site/#enable-edit-icon","title":"Enable Edit Icon","text":"<p>To enable the Edit icon on all pages, you must add the edit_uri and the content.action.edit under the theme features area.</p> <pre><code>edit_uri: edit/master/docs/\n</code></pre> <pre><code>    theme:\n        features:\n            - content.action.edit\n</code></pre>"},{"location":"how-we-built-this-site/#conda-vs-venv","title":"Conda vs VENV","text":"<p>There are two choices for virtual environments.  We can use the native Python venv or use Conda.  venv is simle but is only designed for pure Python projects.  We imagine that this site could use JavaScript and other langauges in the future, so we picked Conda. There is nothing on this microsite that prevents you from using one or the other.  See the ChatGPT Analysis Here.</p> <p>Here is the conda script that we ran to create a new mkdocs environment that also supports the material social imaging libraries.</p> <pre><code>conda deactivate\nconda create -n mkdocs python=3\nconda activate mkdocs\npip install mkdocs \"mkdocs-material[imaging]\"\n</code></pre>"},{"location":"how-we-built-this-site/#mkdocs-commands","title":"Mkdocs Commands","text":"<p>There are three simple mkdoc commands we use.</p>"},{"location":"how-we-built-this-site/#local-build","title":"Local Build","text":"<pre><code>mkdocs build\n</code></pre> <p>This builds your website in a folder called <code>site</code>.  Use this to test that the mkdocs.yml site is working and does not have any errors.</p>"},{"location":"how-we-built-this-site/#run-a-local-server","title":"Run a Local Server","text":"<pre><code>mkdocs serve\n</code></pre> <p>This runs a server on <code>http://localhost:8000</code>. Use this to test the display formatting locally before you push your code up to the GitHub repo.</p> <pre><code>mkdoc gh-deploy\n</code></pre> <p>This pushes everything up to the GitHub Pages site. Note that it does not commit your code to GitHub.</p>"},{"location":"how-we-built-this-site/#mkdocs-material-social-tags","title":"Mkdocs Material Social Tags","text":"<p>We are using the Material Social tags.  This is a work in progress!</p> <p>Here is what we have learned.</p> <ol> <li>There are extensive image processing libraries that can't be installed with just pip.  You will need to run a tool like brew on the Mac to get the libraries installed.</li> <li>Even after <code>brew</code> installs the libraries, you have to get your environment to find the libraries.  The only way I could get that to work was to set up a local UNIX environment variable.</li> </ol> <p>Here is the brew command that I ran:</p> <pre><code>brew install cairo freetype libffi libjpeg libpng zlib\n</code></pre> <p>I then had to add the following to my ~/.zshrc file:</p> <pre><code>export DYLD_FALLBACK_LIBRARY_PATH=/opt/homebrew/lib\n</code></pre> <p>Note that I am running on a Mac with Apple silicon.  This means that the image libraries that brew downloads must be specific to the Mac Arm instruction set.</p>"},{"location":"how-we-built-this-site/#image-generation-and-compression","title":"Image Generation and Compression","text":"<p>I have used ChatGPT to create most of my images.  However, they are too large for most websites.  To compress them down I used  https://tinypng.com/ which is a free tool  for compressing png images without significant loss of quality.  The files created with ChatGPT are typically around 1-2 MB.  After  using the TinyPNG site the size is typically around 200-300KB.</p> <ul> <li>Cover images for blog post #4364</li> <li>Discussion on overriding the Social Card Image</li> </ul>"},{"location":"license/","title":"Creative Commons License","text":"<p>All content in this repository is governed by the following license agreement:</p>"},{"location":"license/#license-type","title":"License Type","text":"<p>Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0 DEED)</p>"},{"location":"license/#link-to-license-agreement","title":"Link to License Agreement","text":"<p>https://creativecommons.org/licenses/by-nc-sa/4.0/deed.en</p>"},{"location":"license/#your-rights","title":"Your Rights","text":"<p>You are free to:</p> <ul> <li>Share \u2014 copy and redistribute the material in any medium or format</li> <li>Adapt \u2014 remix, transform, and build upon the material</li> </ul> <p>The licensor cannot revoke these freedoms as long as you follow the license terms.</p>"},{"location":"license/#restrictions","title":"Restrictions","text":"<ul> <li>Attribution \u2014 You must give appropriate credit, provide a link to the license, and indicate if changes were made. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use.</li> <li>NonCommercial \u2014 You may not use the material for commercial purposes.</li> <li>ShareAlike \u2014 If you remix, transform, or build upon the material, you must distribute your contributions under the same license as the original.</li> <li>No additional restrictions \u2014 You may not apply legal terms or technological measures that legally restrict others from doing anything the license permits.</li> </ul> <p>Notices</p> <p>You do not have to comply with the license for elements of the material in the public domain or where your use is permitted by an applicable exception or limitation.</p> <p>No warranties are given. The license may not give you all of the permissions necessary for your intended use. For example, other rights such as publicity, privacy, or moral rights may limit how you use the material.</p> <p>This deed highlights only some of the key features and terms of the actual license. It is not a license and has no legal value. You should carefully review all of the terms and conditions of the actual license before using the licensed material.</p>"},{"location":"references/","title":"References","text":"<p>Powerful A.I. Is Coming. We\u2019re Not Ready. - New York Times - March 14, 2025 - By Kevin Roose - Three arguments for taking progress toward artificial general intelligence, or A.G.I., more seriously \u2014 whether you\u2019re an optimist or a pessimist.</p> <p>Site References</p> <ol> <li>mkdocs - https://www.mkdocs.org/ - this is our tool for building the website.  It converts Markdown into HTML in the <code>site</code> directory.</li> <li>mkdocs material theme - https://squidfunk.github.io/mkdocs-material/ - this is the theme for our site.  The theme adds the user interface elements that give our site the look and feel.  It also has the features such as social cards.</li> <li>GitHub Pages - https://pages.github.com/ - this is the free tool for hosting public websites created by mkdocs</li> <li>Markdown - https://www.mkdocs.org/user-guide/writing-your-docs/#writing-with-markdown - this is the format we use for text.  It allows us to have headers, lists, tables, links and images without learning HTML.</li> <li>Deploy Mkdocs GitHub Action - https://github.com/marketplace/actions/deploy-mkdocs - this is the tool we use to automatically build our site after edits are checked in with Git.</li> <li>Git Book - https://git-scm.com/book/en/v2 - a useful book on Git.  Just read the first two chapters to learn how to check in new code.</li> <li>Conda - https://conda.io/ - this is a command line tool that keeps our Python libraries organized for each project.</li> <li>VS Code - https://code.visualstudio.com/ - this is the integrated development environment we use to mange the files on our website.</li> <li>Markdown Paste - https://marketplace.visualstudio.com/items?itemName=telesoho.vscode-markdown-paste-image - this is the VS code extension we use to make sure we keep the markdown format generated by ChatGPT.</li> </ol>"},{"location":"chapters/agi-predicted-dates/","title":"AGI Predicted Dates","text":"<p>Prompt</p> <p>I am interested in when experts think that we will reach a level of AI called \"Artificial General Intelligence\" or AGI.  Although I understand that the term is not precisely defined, it is a widely used benchmark date.  Please gather everything you know about what date experts in AI will predict we will  archive this level of intelligence.  Summarize your results in a three column table with the following format:</p> <p>Column 1:  Name of person or organization Column 2: Expected year/month Column 3: Note on credibility of the person or organization</p> <p>Here is a summary of predictions regarding the expected arrival of Artificial General Intelligence (AGI), compiled from various experts and organizations:</p>"},{"location":"chapters/agi-predicted-dates/#openai-4o-response","title":"OpenAI 4o Response","text":"Name or Organization Expected Year/Month Credibility Note Ray Kurzweil 2029 Renowned futurist and Google AI researcher; has consistently predicted AGI by 2029 since 2005. Daniel Kokotajlo / AI Futures Project 2027 Former OpenAI researcher leading the AI Futures Project; released \"AI 2027\" forecast predicting AGI by end of 2027. Dario Amodei (Anthropic CEO) 2026 CEO of AI safety-focused company Anthropic; predicts AGI by 2026, describing it as a system smarter than a Nobel laureate across many fields. Sam Altman (OpenAI CEO) 2025 or soon after CEO of OpenAI; believes AGI is imminent, possibly arriving in 2025 or shortly thereafter. Geoffrey Hinton 5\u201320 years (from 2023) Pioneer in deep learning; revised his estimate in 2023 to AGI arriving within 5 to 20 years. Demis Hassabis (DeepMind CEO) 2030\u20132035 CEO of Google DeepMind; forecasts AGI within 5 to 10 years as of 2025, emphasizing its potential for scientific discovery. Shane Legg (DeepMind Co-founder) 2028 Co-founder of DeepMind; estimated a 50% chance of AGI by 2028. AI Multiple (Survey of 8,590 predictions) 2040\u20132050 Aggregated analysis of expert predictions; estimates over 50% chance of AGI emergence between 2040 and 2050, with 90% likelihood by 2075. Our World in Data (Multiple Surveys) 2060s Analysis across three surveys; more than half of experts think there's a 50% chance of human-level AI before some point in the 2060s. AI Impacts (2022 Survey) 2040 (50% chance) Surveyed machine learning researchers; median estimate for AGI arrival is 2040 with a 50% probability. Ari Allyn-Feuer &amp; Ted Sanders (Academic Paper) &lt;1% chance by 2043 Researchers argue that transformative AGI by 2043 is less than 1% likely, considering necessary advancements in software, hardware, and sociopolitical factors. Yann LeCun (Meta Chief AI Scientist) Decades away Chief AI Scientist at Meta; believes AGI is not imminent and will evolve gradually over decades, not through a single breakthrough. Andrew Ng (AI Researcher) Uncertain Prominent AI researcher; remains skeptical of near-term AGI and urges caution regarding claims of its imminence. <p>This table reflects a range of expert opinions on AGI timelines, highlighting the diversity of thought in the field.</p>"},{"location":"chapters/agi-predicted-dates/#openai-deep-research-results","title":"OpenAI Deep Research Results","text":"<p>Great, I\u2019ll gather recent (last 2\u20133 years) predictions about when AGI is expected to emerge, including input from top researchers, expert community surveys, think tanks, and reputable media and blog sources\u2014with credibility notes for each.</p> <p>I\u2019ll return the results in a table with the name, predicted year or month, and a credibility assessment. I\u2019ll get started and update you once it\u2019s ready.</p>"},{"location":"chapters/agi-predicted-dates/#recent-predictions-table-agi","title":"Recent Predictions Table AGI","text":"<p>This table only includes recent prediction (2022\u20132025)</p> <ol> <li>Only include recent predictions in the last 2-3 years.</li> <li>Include surveys of broader expert communities, think tanks, and forecasting platforms</li> <li>Include reputable media coverage and expert blog posts but justify why the source is reputable</li> </ol> Predictor (Person or Organization) Predicted Timeline for AGI Credibility / Role (Why this source is notable) Sam Altman 2025 \u2013 Altman said he is \u201cconfident we know how to build AGI\u201d and expects the first true AGI systems by 2025. CEO of OpenAI (the lab behind ChatGPT); prominent AI leader driving AGI development. Elon Musk 2025\u20132026 \u2013 Musk predicted AI \u201csmarter than the smartest human\u201d will likely emerge by 2025 (within a year or two as of 2024). CEO of Tesla and founder of xAI; co-founder of OpenAI, known tech visionary (albeit often optimistic). Dario Amodei 2026 \u2013 Believes AGI by 2026 is plausible, describing future AI as \u201ca country of geniuses in a data center\u201d. CEO of Anthropic (AI safety-focused startup); former OpenAI research director, respected in AI research. Richard Socher ~2027 \u2013 Predicted AGI (by one definition, automating ~80% of jobs) in \u201cthree to five years\u201d (i.e. around 2027\u20132028). Renowned NLP researcher; former Salesforce Chief Scientist and current CEO of You.com (AI search startup). Ben Goertzel 2028 \u2013 Expects \u201chuman-level AGI within\u2026three to five years\u201d (as of late 2024), roughly by 2028, aligning with Ray Kurzweil\u2019s 2029 forecast. CEO of SingularityNET and chairman of the AGI Society; AI researcher who helped popularize the term \u201cAGI\u201d. Ray Kurzweil 2029 \u2013 Projects human-level AI by 2029, a prediction he first made in 2005 and still maintains as of 2024. (He also foresees a tech \u201cSingularity\u201d by 2045.) Noted futurist and Google engineer; former director of engineering at Google, author of The Singularity Is Near, with a track record of tech predictions. Demis Hassabis 2030 \u2013 Estimates 5\u201310 years from now for AGI: in a 2023 interview he said AGI is likely \u201cbetween five and 10 years away,\u201d i.e. by \\~2030. CEO and co-founder of Google DeepMind (leading AI research lab behind AlphaGo); 2023 Turing Award equivalent (Nobel in Chemistry for AlphaFold). Geoffrey Hinton 2030s \u2013 Warned in 2023 that superhuman AI might be achieved \u201cin as little as five years\u201d (though with low confidence), giving a 5\u201320 year range for AGI. Turing Award\u2013winning professor emeritus (University of Toronto) and ex-Google researcher; dubbed the \u201cGodfather of AI\u201d for pioneering deep learning. Metaculus (Community Forecast) 2031 \u2013 The median prediction on Metaculus (a crowdsourced forecasting platform) expects AGI around 2031 for the first human-level AI system. Metaculus community (thousands of forecasters) aggregating expert predictions; known for calibrated tech forecasts. Conjecture (2023 Staff Survey) Before 2035 \u2013 A 2023 survey of researchers at Conjecture (an AI research startup) found unanimous expectation of AGI by \u201cbefore 2035\u201d. Conjecture (AI alignment-focused research lab led by Connor Leahy); staff comprised of AI researchers/engineers actively working on AGI safety. Shane Legg 2037 \u2013 Estimated an 80% probability of AGI by 2037 (within 13 years, as of 2023). Co-founder of DeepMind (acquired by Google); prominent AI researcher who has long contemplated AGI timelines. Ajeya Cotra 2040 \u2013 Forecasted 50% chance of AGI by 2040, in an analysis updated in 2022 (significantly sooner than her 2020 estimate of 2050). Senior AI research analyst at Open Philanthropy (a think tank); known for rigorous modeling of AI progress (\u201cbiological anchors\u201d report for AGI timelines). AI Impacts (2023 Expert Survey) 2047 \u2013 The 2023 survey of 2,778 AI researchers by AI Impacts found a median guess of 50% chance by 2047 for human-level AI (down from 2059 in their 2022 survey). Large-scale academic survey (conducted by the nonprofit AI Impacts and researchers like Katja Grace); provides aggregated expert opinion from hundreds of AI academics."},{"location":"chapters/agi-predicted-dates/#references","title":"References","text":"<ol> <li> <p>Ray Kurzweil predicts AGI by 2029 -- June 29, 2024 -- The Guardian -- Futurist and former Google engineer known for accurate tech trend forecasting.</p> </li> <li> <p>Sam Altman: Confident We Know How to Build AGI -- Nov 2024 -- Business Insider -- OpenAI CEO outlining near-term expectations for AGI.</p> </li> <li> <p>Elon Musk Says Superintelligent AI Could Arrive in 2025 -- Apr 2024 -- Business Insider -- Known for optimistic timelines; discusses AGI's implications.</p> </li> <li> <p>Dario Amodei Says AGI Might Come by 2026 -- Nov 2024 -- Business Insider -- CEO of Anthropic and former OpenAI research director.</p> </li> <li> <p>Ben Goertzel Aligns with Kurzweil on AGI Timeline -- Mar 2024 -- Interesting Engineering -- AGI researcher and founder of SingularityNET.</p> </li> <li> <p>Richard Socher Predicts AGI by 2027--2028 -- Apr 12, 2023 -- TIME Magazine -- Renowned NLP researcher and You.com CEO.</p> </li> <li> <p>Demis Hassabis Says AGI Likely by 2030--2035 -- Apr 2025 -- TIME Magazine -- DeepMind CEO and AI pioneer.</p> </li> <li> <p>Geoffrey Hinton Warns AGI Could Be Just 5--20 Years Away -- Jul 2023 -- Business Insider -- Turing Award winner and deep learning pioneer.</p> </li> <li> <p>Metaculus Forecast: AGI by 2031 -- Ongoing (last updated 2025) -- Metaculus -- Crowdsourced forecasting platform with expert users.</p> </li> <li> <p>Conjecture Survey: AGI Before 2035 -- Dec 2023 -- LessWrong -- Independent safety-oriented research lab with internal staff polling.</p> </li> <li> <p>Shane Legg: 80% Chance of AGI by 2037 -- Dec 2023 -- LessWrong -- DeepMind cofounder cited in internal AGI survey discussions.</p> </li> <li> <p>Ajeya Cotra: 50% Chance of AGI by 2040 -- Updated 2022 -- Open Philanthropy -- Think tank researcher with widely cited AGI modeling framework.</p> </li> <li> <p>AI Impacts 2023 Survey: Median AGI Arrival by 2047 -- Oct 2023 -- AI Impacts -- Academic nonprofit aggregating views of nearly 3,000 AI researchers.</p> </li> </ol> <p>Would you like me to embed these links directly into the prediction table for clarity?</p> <p>OpenAI Deep Research</p>"},{"location":"chapters/benchmarking-ai/","title":"Benchmarking","text":"<p>Prompt</p> <p>Create a new chapter for this course on the topic of benchmarking AI.</p> <p>Begin with a gentle slow step-by-step introduction to how we measure the capabilities of a large-language model.</p> <p>Introduce some simple question and answer benchmarks for testing how capable a LLM is and answering simple general purpose questions where the answer can be objectively tested as being correct.  Describe how these question answering benchmarks are created and how they have evolved as LLMs became more capable.</p> <p>Next, generate some content around more specialized benchmarks such as identifying items in an image, writing code and complex language tasks such as logic and reasoning.</p> <p>Also mention how humans can objectively compare things like document summarization by comparing the quality of different responses from different models,  </p> <p>Generate a list of key benchmarks: From ImageNet to modern benchmarks like MMLU and HumanEval</p> <p>Whenever appropriate describe an table, chart, diagram or image that can be inserted into the text to make topics clear.</p> <p>End with an Appendix listing some of the key LLM benchmarks and trend charts for each of these benchmarks.</p>"},{"location":"chapters/benchmarking-ai/#response","title":"Response","text":"<p>I'll create a new chapter for your course on benchmarking AI, following the MkDocs standards. Here's the chapter content:</p>"},{"location":"chapters/benchmarking-ai/#benchmarking-ai-measuring-progress-and-capabilities","title":"Benchmarking AI: Measuring Progress and Capabilities","text":""},{"location":"chapters/benchmarking-ai/#introduction-to-ai-benchmarking","title":"Introduction to AI Benchmarking","text":"<p>Benchmarking AI systems, particularly Large Language Models (LLMs), is essential to understanding their capabilities, tracking progress, and identifying limitations. This chapter explores how we measure AI performance through various benchmarks and what these measurements tell us about AI development.</p>"},{"location":"chapters/benchmarking-ai/#why-we-benchmark-ai","title":"Why We Benchmark AI","text":"<p>Before diving into specific benchmarks, it's important to understand why benchmarking matters:</p> <ul> <li>Provides objective measures of progress over time</li> <li>Enables comparison between different models and approaches</li> <li>Identifies strengths and weaknesses in current systems</li> <li>Guides future research and development efforts</li> <li>Helps organizations make informed decisions about AI adoption</li> </ul>"},{"location":"chapters/benchmarking-ai/#the-evolution-of-ai-benchmarks","title":"The Evolution of AI Benchmarks","text":"<p>AI benchmarking has evolved significantly alongside the capabilities of the models being measured:</p> <ol> <li>Early benchmarks focused on narrow tasks like image classification or basic natural language processing</li> <li>Mid-generation benchmarks expanded to more complex reasoning and knowledge tasks</li> <li>Current benchmarks test for sophisticated capabilities including multimodal understanding, reasoning, and alignment with human values</li> </ol> <p>[Figure: Timeline showing the evolution of AI benchmarks from 2012 to present, highlighting key milestones and capability thresholds]</p>"},{"location":"chapters/benchmarking-ai/#question-answering-benchmarks-the-foundation-of-llm-evaluation","title":"Question-Answering Benchmarks: The Foundation of LLM Evaluation","text":""},{"location":"chapters/benchmarking-ai/#how-qa-benchmarks-work","title":"How Q&amp;A Benchmarks Work","text":"<p>Question-answering benchmarks provide a straightforward way to assess an LLM's knowledge and reasoning abilities:</p> <ol> <li>A dataset of questions with known correct answers is compiled</li> <li>The model generates answers to these questions without having seen them during training</li> <li>Responses are evaluated against the correct answers, typically using accuracy metrics</li> <li>Results are aggregated to produce an overall performance score</li> </ol>"},{"location":"chapters/benchmarking-ai/#creating-effective-qa-benchmarks","title":"Creating Effective Q&amp;A Benchmarks","text":"<p>The development of these benchmarks follows several key steps:</p> <ol> <li>Question collection - Gathering questions from diverse sources or having experts create them</li> <li>Answer validation - Ensuring correct answers are established and verified</li> <li>Categorization - Organizing questions into domains (science, history, etc.)</li> <li>Difficulty calibration - Including a range of difficulty levels</li> <li>Bias mitigation - Reducing cultural, geographical, or other biases</li> </ol>"},{"location":"chapters/benchmarking-ai/#evolution-of-qa-benchmarks","title":"Evolution of Q&amp;A Benchmarks","text":"<p>As LLMs have grown more capable, Q&amp;A benchmarks have evolved to present more challenging tests:</p>"},{"location":"chapters/benchmarking-ai/#first-generation-basic-knowledge-retrieval","title":"First Generation: Basic Knowledge Retrieval","text":"<ul> <li>Simple factual questions with straightforward answers</li> <li>Example: \"What is the capital of France?\"</li> </ul>"},{"location":"chapters/benchmarking-ai/#second-generation-multi-step-reasoning","title":"Second Generation: Multi-step Reasoning","text":"<ul> <li>Questions requiring integration of multiple facts</li> <li>Example: \"If Country A has twice the population of Country B, and Country B has 30 million people and is half the size of Country C, how many people per square mile are in Country A compared to Country C?\"</li> </ul>"},{"location":"chapters/benchmarking-ai/#third-generation-nuanced-understanding","title":"Third Generation: Nuanced Understanding","text":"<ul> <li>Questions requiring contextual understanding, handling of ambiguity, and recognition of implied information</li> <li>Example: \"In what ways did the economic policies of the 1920s contribute to the Great Depression?\"</li> </ul> <p>[Table: Comparison of first, second, and third generation Q&amp;A benchmarks showing example questions, evaluation methods, and average model performance]</p>"},{"location":"chapters/benchmarking-ai/#specialized-benchmarks-beyond-general-knowledge","title":"Specialized Benchmarks: Beyond General Knowledge","text":""},{"location":"chapters/benchmarking-ai/#multimodal-understanding","title":"Multimodal Understanding","text":"<p>As AI systems have developed capabilities beyond text, benchmarks now test how well models can:</p> <ul> <li>Identify objects, actions, and relationships in images</li> <li>Understand diagrams and visual data</li> <li>Connect visual and textual information</li> </ul>"},{"location":"chapters/benchmarking-ai/#key-multimodal-benchmarks","title":"Key Multimodal Benchmarks:","text":"<ol> <li>ImageNet - The pioneering image classification dataset that catalyzed the deep learning revolution</li> <li>VQA (Visual Question Answering) - Tests ability to answer questions about images</li> <li>MMMU (Massive Multimodal Understanding) - Evaluates understanding across text, images, and diagrams</li> </ol>"},{"location":"chapters/benchmarking-ai/#coding-and-problem-solving-benchmarks","title":"Coding and Problem-Solving Benchmarks","text":"<p>These benchmarks assess an AI's ability to understand programming concepts, generate functional code, and solve computational problems:</p> <ol> <li>HumanEval - Tests the ability to generate functionally correct Python code</li> <li>MBPP (Mostly Basic Programming Problems) - Evaluates basic programming skills</li> <li>CodeContests - Challenges models with competitive programming problems</li> </ol>"},{"location":"chapters/benchmarking-ai/#how-coding-benchmarks-work","title":"How Coding Benchmarks Work:","text":"<ol> <li>The model is given a problem description or function specification</li> <li>It generates a solution in the requested programming language</li> <li>The solution is executed against test cases to verify correctness</li> <li>Results are evaluated on metrics like pass rate and code quality</li> </ol> <p>[Diagram: Visual representation of the coding benchmark process from problem statement to evaluation]</p>"},{"location":"chapters/benchmarking-ai/#logic-and-reasoning-benchmarks","title":"Logic and Reasoning Benchmarks","text":"<p>These benchmarks test an AI's capacity for higher-order thinking:</p> <ol> <li>GSM8K - Grade school math word problems requiring multi-step reasoning</li> <li>MMLU (Massive Multitask Language Understanding) - Tests knowledge across 57 subjects requiring specialized expertise</li> <li>Big-Bench Hard - Particularly challenging reasoning tasks</li> </ol>"},{"location":"chapters/benchmarking-ai/#human-evaluation-benchmarks","title":"Human Evaluation Benchmarks","text":"<p>Not all capabilities can be measured through automated metrics. For tasks like summarization, creative writing, or helpfulness, human evaluators compare outputs:</p> <ol> <li>Human preference ratings - People rank outputs from different models</li> <li>Side-by-side comparisons - Direct comparison of multiple models on the same tasks</li> <li>Turing-test inspired evaluations - Assessing whether outputs appear human-generated</li> </ol>"},{"location":"chapters/benchmarking-ai/#key-benchmarks-in-ai-evaluation","title":"Key Benchmarks in AI Evaluation","text":""},{"location":"chapters/benchmarking-ai/#general-knowledge-and-reasoning","title":"General Knowledge and Reasoning","text":"<ol> <li>MMLU (Massive Multitask Language Understanding)</li> <li>Tests knowledge across 57 subjects including STEM, humanities, social sciences</li> <li>Measures both breadth and depth of knowledge</li> <li>Human expert performance: ~90%</li> <li> <p>State-of-the-art AI (2024): ~95%</p> </li> <li> <p>TruthfulQA</p> </li> <li> <p>Evaluates whether models give accurate rather than common but incorrect answers</p> </li> <li>Tests resistance to reproducing misconceptions and falsehoods</li> <li> <p>Particularly challenging for many LLMs</p> </li> <li> <p>GPQA (Graduate-level Professional Question Answering)</p> </li> <li> <p>Expert-level questions in medicine, law, and other specialized fields</p> </li> <li>Requires deep domain expertise beyond general knowledge</li> </ol>"},{"location":"chapters/benchmarking-ai/#problem-solving-and-reasoning","title":"Problem Solving and Reasoning","text":"<ol> <li> <p>GSM8K (Grade School Math 8K)</p> </li> <li> <p>8,000 grade school math word problems requiring multi-step reasoning</p> </li> <li>Tests ability to break down problems and apply mathematical concepts</li> <li> <p>Measures improvement in chain-of-thought reasoning capabilities</p> </li> <li> <p>MATH</p> </li> <li> <p>High school and college-level mathematics problems</p> </li> <li>Requires formal mathematical reasoning and proofs</li> <li> <p>One of the most challenging benchmarks for current LLMs</p> </li> <li> <p>Big-Bench Hard</p> </li> <li> <p>Collection of extremely difficult tasks across multiple domains</p> </li> <li>Designed to identify the frontier of AI capabilities</li> </ol>"},{"location":"chapters/benchmarking-ai/#coding-and-technical-skills","title":"Coding and Technical Skills","text":"<ol> <li> <p>HumanEval</p> </li> <li> <p>164 hand-written programming problems</p> </li> <li>Tests functional correctness of generated code</li> <li> <p>Measures both understanding of programming concepts and ability to implement them</p> </li> <li> <p>APPS (Automated Programming Progress Standard)</p> </li> <li> <p>Coding problems of varying difficulty from introductory to competition-level</p> </li> <li>Evaluates broader programming abilities across different contexts</li> </ol> <p>[Graph: Performance trends of leading LLMs on HumanEval from 2021-2025, showing rapid improvement]</p>"},{"location":"chapters/benchmarking-ai/#multimodal-understanding_1","title":"Multimodal Understanding","text":"<ol> <li> <p>MSCOCO Caption</p> </li> <li> <p>Tests ability to generate accurate descriptions of images</p> </li> <li> <p>Evaluates visual understanding and natural language generation</p> </li> <li> <p>GQA (Graph Question Answering)</p> </li> <li> <p>Tests reasoning about visual relationships in images</p> </li> <li>Requires connecting visual elements with conceptual understanding</li> </ol>"},{"location":"chapters/benchmarking-ai/#safety-and-alignment","title":"Safety and Alignment","text":"<ol> <li> <p>ToxiGen</p> </li> <li> <p>Evaluates model's tendency to generate harmful content</p> </li> <li> <p>Tests safeguards against producing inappropriate responses</p> </li> <li> <p>Anthropic's Helpful and Harmless benchmarks</p> </li> <li> <p>Assesses balance between helpfulness and refusal of harmful requests</p> </li> <li>Measures alignment with human values and instruction-following</li> </ol>"},{"location":"chapters/benchmarking-ai/#benchmarking-limitations-and-considerations","title":"Benchmarking Limitations and Considerations","text":"<p>While benchmarks provide valuable information about AI capabilities, they have important limitations:</p> <ol> <li>Benchmark saturation - As models are optimized for specific benchmarks, they may become less representative of real-world performance</li> <li>Memorization concerns - Models might memorize benchmark answers rather than demonstrating true understanding</li> <li>Coverage gaps - Many important capabilities are difficult to measure objectively</li> <li>Cultural bias - Many benchmarks reflect Western knowledge and values</li> <li>Moving targets - The definition of \"intelligence\" evolves as AI advances</li> </ol> <p>[Diagram: Visual representation of the \"benchmarking cycle\" showing how benchmark creation leads to model optimization which necessitates more challenging benchmarks]</p>"},{"location":"chapters/benchmarking-ai/#practical-applications-of-benchmark-data","title":"Practical Applications of Benchmark Data","text":"<p>Organizations can use benchmark information to:</p> <ol> <li>Select appropriate AI systems for specific tasks based on relevant benchmark performance</li> <li>Set realistic expectations about AI capabilities and limitations</li> <li>Track progress in areas relevant to organizational needs</li> <li>Identify capability gaps where human expertise remains essential</li> </ol>"},{"location":"chapters/benchmarking-ai/#workshop-activity-creating-a-custom-benchmark","title":"Workshop Activity: Creating a Custom Benchmark","text":"<p>In this hands-on session, participants will:</p> <ol> <li>Identify key tasks relevant to their organization</li> <li>Design evaluation metrics aligned with organizational goals</li> <li>Create sample benchmark questions/tasks</li> <li>Discuss evaluation methodologies for their custom benchmark</li> </ol>"},{"location":"chapters/benchmarking-ai/#appendix-key-ai-benchmarks-and-performance-trends","title":"Appendix: Key AI Benchmarks and Performance Trends","text":""},{"location":"chapters/benchmarking-ai/#mmlu-massive-multitask-language-understanding","title":"MMLU (Massive Multitask Language Understanding)","text":"<ul> <li>Description: 57 subjects across STEM, humanities, social sciences at high school to expert level</li> <li>Significance: Broad measure of knowledge across domains</li> <li>Performance Trend: Crossed human average performance in 2022, approaching expert levels by 2024</li> <li>Chart: Line graph showing performance improvements from GPT-3 through Claude 3.7 Sonnet</li> </ul>"},{"location":"chapters/benchmarking-ai/#humaneval","title":"HumanEval","text":"<ul> <li>Description: Hand-written programming problems testing functional correctness</li> <li>Significance: Key measure of coding ability</li> <li>Performance Trend: Improved from &lt;30% pass rate in 2021 to &gt;90% for leading models in 2024</li> <li>Chart: Bar chart comparing pass rates across major models and versions</li> </ul>"},{"location":"chapters/benchmarking-ai/#gsm8k","title":"GSM8K","text":"<ul> <li>Description: Grade school math problems requiring multi-step reasoning</li> <li>Significance: Tests mathematical reasoning and problem decomposition</li> <li>Performance Trend: Dramatic improvements with chain-of-thought prompting techniques</li> <li>Chart: Line graph showing accuracy improvements, with notable jumps at key methodological innovations</li> </ul>"},{"location":"chapters/benchmarking-ai/#truthfulqa","title":"TruthfulQA","text":"<ul> <li>Description: Tests factual accuracy on questions where common beliefs may be false</li> <li>Significance: Measures resistance to reproducing misconceptions</li> <li>Performance Trend: Slower improvement than other benchmarks, highlighting ongoing challenges</li> <li>Chart: Comparison of truthfulness scores across model generations</li> </ul>"},{"location":"chapters/benchmarking-ai/#visual-understanding-benchmarks","title":"Visual Understanding Benchmarks","text":"<ul> <li>Description: Tasks testing understanding of images and visual information</li> <li>Significance: Measures multimodal capabilities</li> <li>Performance Trend: Rapid advancement with specialized multimodal models</li> <li>Chart: Radar chart comparing performance across different visual reasoning tasks</li> </ul> <p>Note: All performance data should be regularly updated as new models and benchmark results are released. Current data shown is as of October 2024.</p>"},{"location":"chapters/current-state/","title":"Current State","text":""},{"location":"chapters/skepticism-of-the-llm-only-path/","title":"Skepticism of the LLM Only Path","text":"<p>On March 4th, 2025 Nature published an article by Nicola Jones that surveyed AI researchers on our progress toward achieving Artificial General Intelligence (AGI).  Here is a summary of some points this article says about the limitations of current LLMs.</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#summary-of-llm-limitations-according-to-the-nature-article","title":"Summary of LLM Limitations According to the Nature Article","text":"<p>The Nature article by Nicola Jones, published on March 4, 2025, reports on a survey conducted by the Association for the Advancement of Artificial Intelligence (AAAI) among AI researchers. Here are the key findings about the limitations of current LLMs:</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#fundamental-architectural-limitations","title":"Fundamental Architectural Limitations","text":"<p>The survey reveals that most respondents are skeptical that the technology underpinning large-language models is sufficient for artificial general intelligence. Specifically:</p> <p>84% of AI professionals believe that relying solely on neural networks is insufficient for achieving AGI. The researchers don't believe that simply scaling up neural networks will bridge the gap to human-level intelligence.</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#scaling-is-not-the-solution","title":"Scaling is Not the Solution","text":"<p>Over 75% believe that merely scaling up existing AI systems won't suffice. The survey reveals that the vast majority of AI researchers doubt that continuing to make neural networks bigger and training them on more data - the approach that has driven recent AI advances - will lead to AGI.</p> <p>an overwhelming 76 percent of respondents said it was \"unlikely\" or \"very unlikely\" to succeed when asked about whether scaling up current AI approaches could lead to achieving AGI.</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#need-for-hybrid-approaches","title":"Need for Hybrid Approaches","text":"<p>a majority advocate for incorporating symbolic AI techniques and more than 60% of those surveyed support the idea that human-level reasoning requires a blend of neural network-based systems and symbolic AI.</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#specific-architectural-limitations","title":"Specific Architectural Limitations","text":"<p>The article, as reported by various sources, indicates that current LLMs lack: - True understanding of concepts (they recognize statistical patterns but don't grasp meaning) - Inherent logical reasoning capabilities - Consistent and reliable decision-making abilities - The ability to structure explicit logic and reasoning</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#priority-shift","title":"Priority Shift","text":"<p>Interestingly, 75% prioritize developing AI with a favorable risk-benefit profile over pursuing AGI, suggesting a shift in research priorities from pure pursuit of AGI to more practical and beneficial AI development.</p> <p>The article paints a picture of the AI research community questioning the fundamental approach that has dominated recent AI development and calling for a fundamental shift in methodology to achieve true artificial general intelligence.</p> <p>The Nature article titled \u201cHow AI can achieve human-level intelligence: researchers call for change in tack\u201d by Nicola Jones, published on March 4, 2025, highlights several limitations of current large language models (LLMs) in achieving artificial general intelligence (AGI).</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#key-limitations-of-current-llms","title":"Key Limitations of Current LLMs","text":"<ol> <li> <p>Lack of True Reasoning and Planning: LLMs excel at generating human-like text but struggle with tasks requiring genuine reasoning and long-term planning. Their outputs are often based on pattern recognition rather than understanding, limiting their ability to perform complex cognitive tasks.</p> </li> <li> <p>Absence of Common Sense and World Modeling: These models lack an inherent understanding of the physical world and common sense reasoning. Without the ability to model real-world scenarios, their applicability in dynamic and unpredictable environments is constrained.</p> </li> <li> <p>Inadequate Internal Deliberation: Unlike humans, LLMs do not possess internal deliberative processes. This deficiency hampers their capacity to evaluate information critically and make informed decisions, which are essential components of human-like intelligence.</p> </li> <li> <p>Overreliance on Data Scaling: The current trajectory of enhancing LLMs primarily involves increasing data and computational resources. However, this approach yields diminishing returns concerning the development of AGI, as it doesn't address foundational cognitive limitations.</p> </li> </ol>"},{"location":"chapters/skepticism-of-the-llm-only-path/#calls-for-a-paradigm-shift","title":"Calls for a Paradigm Shift","text":"<p>The article emphasizes that to progress toward AGI, researchers advocate for a shift from merely scaling existing models to developing new architectures that incorporate elements like symbolic reasoning, embodied cognition, and neural-symbolic integration. Such approaches aim to imbue AI systems with a more profound understanding and flexible problem-solving abilities akin to human intelligence.</p> <p>This perspective aligns with views from AI experts like Yann LeCun, who argue that LLMs, in their current form, are insufficient for achieving human-level intelligence and that alternative methodologies are necessary for meaningful advancement in the field. ([Financial Times][1])</p> <p>In summary, while LLMs have made significant strides in natural language processing, their inherent limitations necessitate a reevaluation of strategies to achieve true artificial general intelligence.</p>"},{"location":"chapters/skepticism-of-the-llm-only-path/#references","title":"References","text":"<ul> <li> <p>Meta AI chief says large language models will not reach human intelligence</p> </li> <li> <p>How AI can achieve human-level intelligence: researchers call for change in tack - Nature - March 4th, 2025 - By Nicola Jones A survey finds that most respondents are skeptical that the technology underpinning large-language models is sufficient for artificial general intelligence.</p> </li> <li> <p>Will AI ever reach human-level intelligence? We asked 5 experts Padlokr</p> </li> <li> <p>Bing Search</p> </li> </ul>"},{"location":"sims/","title":"MicroSimulations for Tracking AI Course","text":""},{"location":"sims/#four-futures","title":"Four Futures","text":"<p>Explore four different rates of change of AI capabilities. Give these four different rates of change precise names.</p> <p>Run the Four Futures</p>"},{"location":"sims/#ai-timeline","title":"AI Timeline","text":"<p>View key events in the history of AI and see how they are spaced.</p> <p>Run the AI Timeline MicroSim</p>"},{"location":"sims/ai-benchmarks-timeline/","title":"AI Benchmarks Timeline","text":"<pre><code>&lt;iframe src=\"https://dmccreary.github.io/deep-learning-course/sims/NAM/main.html\"  height=\"450px\" scrolling=\"no\"\n  style=\"overflow: hidden;\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Run the MicroSim</p> <p>Edit the MicroSim</p> <p>Prompt</p> <p>I would like you to generate a new p5.js MicroSim sketch that displays a timeline view of the key AI benchmarks and when they were introduced.  Please use the format of the file ai-pace-accelerating.js in the Project knowledge area.  Begin with early benchmarks on simple question answering and finish with the most recent benchmarks that focus on specialized topics like coding skills, math skills, medical diagnosis and answering legal questions to pass a bar exam.</p>"},{"location":"sims/ai-pace-accelerating/","title":"The Accelerating Pace of AI","text":"<p>Use these templates to create a MicroSim that can be added to any website with just a single <code>iframe</code> HTML element.</p> <p>You can include this MicroSim in your code by copying the following into your website:</p> <pre><code>&lt;iframe src=\"/mains.html\" width=\"600px\" height=\"450px\" scrolling=\"no\"\n  style=\"overflow: hidden;\"&gt;&lt;/iframe&gt;\n</code></pre> <p></p> <p>Run the Circle Radius MicroSim</p> <p>Edit this MicroSim</p>"},{"location":"sims/autoregressive/","title":"Autoregressive Animation","text":"<p>Prompt</p> <p>Please create a new MicroSim that simulates the prediction of the next token from a sequence of words using a neural network.  The simulation works in phases, with five steps per phase.</p>"},{"location":"sims/autoregressive/#layout-of-the-neural-network-graph","title":"Layout of the neural network graph","text":"<ol> <li>The animation has the five horizontal rows, each with 20 columns of circles.</li> <li>The labels for each row is on the left.</li> <li>The leftMargin is 150 for drawing the labels.</li> <li>The labels on the left column are:     4.1 \"Output\" at y = 100     4.2 \"Hidden Layer\" at y = 200, 300 and 400     4.3 \"Input\" at y = 500</li> <li>The \"Output\" layer has light orange filled circles with r=8.</li> <li>The \"Hidden Layers\" has gray filled circles with r=8</li> <li>The \"Input Layer\" has light blue filled circles with r=8</li> <li>All circles have a thin 1pm black border</li> </ol> <p>Only 16 of the columns are active at any time showing the context window of 16 in the input row.</p> <p>Step 1: Draw 16 arrows from the left-most 16 bottom input layer up to the first hidden layer.  The arrows merge to alternating 8 circles on the lower hidden layer.  Keep the arrows visible for each phase.</p> <p>Step 2: Draw 8 arrows from the lower hidden layer to the middle hidden layer.  Draw them to alternate nodes so the left-most nodes shift one to the right.</p> <p>Step 3. Draw 4 arrows from the middle hidden layer to the top hidden layer.  </p> <p>Step 4. Draw 2 arrows from the top hidden layer to the node in column 17 on the top output row.</p> <p>Step 5. Animate the circle just generated in the 17th row moving to the 17th circle on the bottom row.  Erase all the arrows on the screen.</p> <p>Repeat this animation three times shifting to the right one column each time.</p> <p>Add buttons for Start/Stop and Reset in the control area at the bottom of the animation.</p>"},{"location":"sims/four-futures/","title":"Four AI Futures MicroSim","text":"<pre><code>&lt;iframe src=\"./https://dmccreary.github.io/deep-learning-course/sims/four-futures/main.html\" height=\"400px\" scrolling=\"no\"\n  style=\"overflow: hidden;\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Run the Four Futures MicroSim</p> <p>Edit the Four Futures MicroSim</p> <p>Prompt</p> <p>Create a p5.js MicroSim that generates a line chart. Across the bottom x axis draw an axis label \"Time\". In the center of the Time axis draw a vertical brown line with the label \"Now\".</p> <p>Across the left vertical axis draw an axis with the label \"Rate of Improvement\".</p> <p>Draw four lines on the chart:</p> <ol> <li>Growth and Decline: initial rapid growth but peaking now and will be declining in the future </li> <li>Growth and Flattening: initial rapid growth but flatting out </li> <li>Linear Growth: initial rapid growth but slow linear growth </li> <li>Exponential Growth: initial rapid growth and continued exponential growth</li> </ol> <p>Add a checkbox control to display each option.</p>"},{"location":"sims/learning-graph/","title":"Learning Graph for Deep Learning Course","text":"<p>Run Learning Graph MicroSim</p>"},{"location":"sims/templates/","title":"MicroSim Templates","text":"<pre><code>&lt;iframe src=\"https://dmccreary.github.io/deep-learning-course/sims/NAM/main.html\"  height=\"450px\" scrolling=\"no\"\n  style=\"overflow: hidden;\"&gt;&lt;/iframe&gt;\n</code></pre> <p>Run the MicroSim</p> <p>Edit the MicroSim</p>"},{"location":"sims/timeline/","title":"Deep Learning Timeline MicroSim","text":"<p>Here is a timeline that includes over 100 key events in the field of Deep Learning. The events span from 1935 to present, although events in the last two years had to be entered by hand since ChatGPT o1 is Frozen in Time</p> <p>Run the Deep Learning Timeline MicroSim</p>"},{"location":"stories/","title":"Tracking AI","text":""},{"location":"stories/#yann-lecun","title":"Yann LeCun","text":"<p>This story chronicles Yann LeCun's journey from a curious teenager in 1970s Paris to a pioneering AI researcher who revolutionized machine learning. It follows his development of convolutional neural networks (CNNs) at AT&amp;T Bell Labs for optical character recognition, his forward-thinking establishment of the NYU Center for Data Science in 2012, and his collaboration in founding ICLR to unite the field. The narrative culminates with his 2019 Turing Award and explores his thoughtful skepticism about achieving AGI through large language models alone, emphasizing his belief that future AI systems need comprehensive world models to achieve true intelligence. Throughout, the story illustrates how LeCun combined deep technical innovation with visionary leadership to challenge the status quo and transform what was possible in artificial intelligence.</p> <p>Read the Yann LeCun Story</p>"},{"location":"stories/ai-winters/","title":"The AI Winters: A Tale of Boom and Bust","text":"Narrative Prompt Create a fun and entertaining  story about the \"AI winters\" and how AI grew and died periodically until 2012 before AlexNet. Give as much detail as possible. Include quotes of famous people overpromising when AI would mature.  When appropriate, suggest an image that could be inserted into the story to make the story a form of graphic novel. Describe each image in detail and be consistent across all the images in the story for style.  Image Prompt The Cycles of AI - A grand timeline visualization showing a wavy roller-coaster like path from the 1950s to 2012, with dramatic peaks and valleys marked by calendar pages fluttering away. In the foreground, various symbolic elements from each era (vacuum tubes, robots, neurons) are scattered like autumn leaves. Art style: detailed line art with watercolor washes, muted blues and grays for winter periods, warm oranges and yellows for boom periods."},{"location":"stories/ai-winters/#chapter-1-the-birth-of-a-dream-1950s-1960s","title":"Chapter 1: The Birth of a Dream (1950s-1960s)","text":"Image Prompt  \"The Dartmouth Dreamers\" - A retro-style illustration showing a summer campus scene at Dartmouth College. In the foreground, four enthusiastic men in 1950s attire stand before a chalkboard covered in flowcharts and equations. Speech bubbles above their heads show thought clouds containing robots, thinking machines, and neural networks. Art style: Norman Rockwell meets mid-century scientific illustration.  <p>It was the summer of 1956 when John McCarthy invited fellow dreamers to Dartmouth College for what would become known as the birth of artificial intelligence. McCarthy boldly declared:</p> <p>\"We propose that a 2-month, 10-man study of artificial intelligence be carried out during the summer of 1956... An attempt will be made to find how to make machines use language, form abstractions and concepts, solve kinds of problems now reserved for humans, and improve themselves.\"</p> <p>Herbert Simon and Allen Newell were even bolder, proclaiming at the conference: \"Within ten years, a digital computer will be the world's chess champion\" and \"within twenty years, machines will be capable of doing any work a man can do.\"</p> <p>The optimism was intoxicating. Money poured in from government and industry. Marvin Minsky predicted in 1970: \"In from three to eight years we will have a machine with the general intelligence of an average human being.\"</p>"},{"location":"stories/ai-winters/#chapter-2-the-first-ai-winter-1973-1980","title":"Chapter 2: The First AI Winter (1973-1980)","text":"Image Prompt  \"The Perceptron's Demise\" - A gothic-horror inspired scene showing a mechanical brain or perceptron being dissected on a table, with Minsky and Papert looming over it holding mathematical equations like scalpels. Snow blows through broken windows of a once-grand laboratory. Art style: Edward Gorey-esque crosshatching with dramatic shadows.  <p>The first winter came suddenly. In 1969, Marvin Minsky and Seymour Papert published \"Perceptrons,\" mathematically proving that simple neural networks couldn't even solve basic problems like XOR. The book was like a bucket of ice water on the field's optimism.</p> <p>Government funding dried up after the 1973 Lighthill Report called AI research a dead end. Labs shuttered. Graduate students fled to other fields. The promised thinking machines had failed to materialize, and the world lost patience.</p>"},{"location":"stories/ai-winters/#chapter-3-the-expert-systems-spring-1980-1987","title":"Chapter 3: The Expert Systems Spring (1980-1987)","text":"Image Prompt  \"The Rule Kingdom\" - An illustration in the style of a medieval manuscript showing programmers as monks transcribing thousands of IF-THEN rules into giant books. In the background, executives throw gold coins at them. A mechanical decision tree towers like a cathedral spire. Art style: illuminated manuscript meets corporate tech, rich golds and blues.  <p>Like crocuses pushing through snow, AI began to bloom again with expert systems. These rule-based programs promised to capture human expertise in code. Edward Feigenbaum declared:</p> <p>\"The world is moving from the industrial age to the age of knowledge... knowledge is power.\"</p> <p>DEC's XCON system saved the company $40 million a year configuring computers. Japan announced their Fifth Generation Computer project in 1982, promising to create intelligent computers by 1992. The AI race was back on.</p>"},{"location":"stories/ai-winters/#chapter-4-the-second-ai-winter-1987-1993","title":"Chapter 4: The Second AI Winter (1987-1993)","text":"Image Prompt  \"The Symbolic Collapse\" - A surreal Dali-esque landscape where giant IF-THEN rules melt like clocks, expert system books crumble to dust, and abandoned LISP machines rust in a wasteland. Government officials and investors flee under dark storm clouds. Art style: Salvador Dali meets corporate dystopia.  <p>But expert systems hit a wall. They were brittle, expensive to maintain, and couldn't handle the messy real world. By 1987, the AI hardware market collapsed. The Japanese Fifth Generation project failed to deliver on its promises.</p> <p>Rodney Brooks wrote a scathing critique in 1990: \"The symbol system hypothesis upon which classical AI is based is fundamentally flawed.\" Companies that had bet heavily on AI went bankrupt. Another winter had begun.</p>"},{"location":"stories/ai-winters/#chapter-5-the-machine-learning-spring-1993-2001","title":"Chapter 5: The Machine Learning Spring (1993-2001)","text":"Image Prompt  \"The Data Dawn\" - A scene showing nerdy programmers in 90s attire feeding stacks of data into computers while decision trees and support vector machines grow like plants from the machines. In the background, the early internet is represented as glowing fiber optic cables spreading like vines. Art style: cyber-renaissance, mixing classical composition with 90s tech aesthetics.  <p>AI quietly reinvented itself. Machine learning algorithms that could learn from data began to show promise. IBM's Deep Blue defeated world chess champion Garry Kasparov in 1997. Search engines started using statistical methods to rank web pages.</p> <p>Vladimir Vapnik developed support vector machines. Yann LeCun built convolutional neural networks for handwriting recognition. But these successes were modest compared to earlier promises.</p>"},{"location":"stories/ai-winters/#chapter-6-the-deep-learning-revolution-2006-2012","title":"Chapter 6: The Deep Learning Revolution (2006-2012)","text":"Image Prompt  \"The Persistent Professor\" - Geoffrey Hinton is shown as a lone figure nurturing a small neural network plant in a cold, abandoned greenhouse. Through broken glass, we can see other researchers walking away. On his desk are piles of rejected grant applications. Art style: melancholic botanical illustration with a hint of steampunk.  <p>While most had abandoned neural networks, Geoffrey Hinton kept the faith. In 2006, he discovered a way to train deep neural networks using a technique called \"pre-training.\" But few paid attention.</p> <p>Hinton later recalled: \"For many years, deep neural networks were considered a joke in the machine learning community.\"</p>"},{"location":"stories/ai-winters/#chapter-7-the-alexnet-breakthrough-2012","title":"Chapter 7: The AlexNet Breakthrough (2012)","text":"Image Prompt  \"The ImageNet Triumph\" - A heroic scene showing AlexNet as a glowing neural network architecture towering over a field of failed algorithms. At its base, the Toronto team raises their GPUs like olympic torches. In the sky, the error rate plummets like a shooting star. Art style: heroic socialist realism meets cyberpunk, dramatic angles and lighting.  <p>And then came 2012. AlexNet's victory at ImageNet shattered decades of conventional wisdom. The 10.8% improvement wasn't just impressive\u2014it was revolutionary.</p> <p>Geoffrey Hinton reflected: \"It was pretty clear that as soon as we got deep learning to work well on ImageNet, the game was over. The people who thought neural nets were never going to work were always going to find reasons why the next thing wouldn't work.\"</p>"},{"location":"stories/ai-winters/#epilogue-the-eternal-spring","title":"Epilogue: The Eternal Spring","text":"Image Prompt  \"The Endless Spring\" - A final panoramic view showing all the AI winters and springs as a continuous landscape, but now with a great branching tree of achievement rising from AlexNet, its branches reaching into a starry sky filled with AI applications. The art style combines all previous styles into a cohesive grand finale.  <p>After AlexNet, there would be no more winters. The combination of big data, GPU acceleration, and improved algorithms had finally unlocked the promise of AI. The boom-and-bust cycle that had characterized the field for half a century was over.</p> <p>The AI winters teach us that technology rarely advances in a straight line. Progress comes in fits and starts, with periods of irrational exuberance followed by crushing disappointment. But sometimes, persistence in the face of skepticism leads to breakthroughs that change everything.</p> <p>As we look to the future of AI, it's worth remembering this history\u2014not just to avoid repeating mistakes, but to appreciate how today's achievements were built on decades of perseverance through the coldest winters.</p>"},{"location":"stories/yann-lecun/","title":"The Visionary who Saw the Future: Yann LeCun's Quest for Intelligent Machines","text":"Show Image Prompt Cover Image: Create a vibrant, tech-optimistic wide-landscape graphic novel cover featuring Yann LeCun as the central figure, depicted in a heroic pose with his arms outstretched toward twin horizons representing past and future. The left horizon shows early computing (1970s-1980s) with vintage computers, handwritten digits, and primitive neural network diagrams, rendered in warm sepia tones. The right horizon explodes with modern AI technology - glowing neural networks, holographic data streams, and interconnected global nodes, rendered in brilliant cyans, magentas, and electric blues.  Behind LeCun, create a dramatic split background where the upper half shows the physical world with realistic buildings, labs, and libraries, while the lower half reveals the digital realm of mathematical concepts materialized as floating equations, converging networks, and architectural visualizations of CNNs. These two realms should blend seamlessly through LeCun's silhouette, with light streaming from his head and heart to represent the flow of ideas.  Above the scene, incorporate three distinct layers: the bottom layer shows early perceptrons and simple neural networks, the middle layer displays complex CNN architectures, and the top layer hints at future world models with intricate cause-and-effect relationships. Use flowing energy lines and glowing nodes to connect these layers, suggesting evolution and continuity. The title 'THE VISIONARY WHO SAW THE FUTURE: YANN LECUN'S QUEST FOR INTELLIGENT MACHINES' should be integrated organically into the design, perhaps formed by neural pathways or data streams. Use a bold, modern typeface that complements the tech-forward aesthetic.  The overall color palette should be bright and optimistic, featuring deep blues for computational elements, warm golds for human insight and eureka moments, vibrant greens for growth and innovation, and luminous whites for breakthrough moments. The style should blend technical accuracy with artistic interpretation, making complex AI concepts visually accessible and inspiring.  Include subtle Easter eggs like the iconic handwritten '5' and '7' digits from his early work, equations floating in the background, and miniature depictions of key moments from his career. The composition should draw the reader's eye in a circular motion, starting from LeCun's determined expression, sweeping through the technological landscape, and returning to his visionary gaze toward the future.  The entire image must be rendered in a wide-landscape format suitable for a graphic novel cover, with dramatic lighting that emphasizes the contrast between challenges overcome and possibilities ahead.  Show Narrative Prompt Please create a detailed fun and entertaining story for high-school students about the AI researcher Yann LeCun.  Generate a narrative text but also create detailed descriptions of graph-novel panels that can be inserted into the story at appropriate places.  The theme of the story is how LeCun challenged the status quo and has overcome obstacles in his career by combining both a deep technical understanding and leadership skills.  Tell how in 1988, LeCun joined the Adaptive Systems Research Department at AT&amp;T Bell Laboratories in Holmdel, New Jersey and worked on machine learning.  Give a detailed background of how his career started doing optical character recognition and computer vision using convolutional neural networks (CNNs).  Tell how in 2012, he became the founding director of the NYU Center for Data Science, before the term \"Data Science\" was popular.  Tell how it 2013, he and Yoshua Bengio co-founded the International Conference on Learning Representations to promote good research in the field of machine learning.  Tell how in March 2019, LeCun won the 2018 Turing Award, sharing it with Yoshua Bengio and Geoffrey Hinton.  Tell how LeCun is extremely skeptical that LLMs alone will ever achieve levels of artificial general intelligence (AGI).  Discuss how LeCun feels that precise world models must be used to achieve AGI.  Our goal is to have you generate the full text of the story, but to turn the story into a graphic novel with many illustrations that explains the arc of  LeCun career.   When appropriate, suggest an image that could be inserted into the story to make the story a graphic novel.   Describe each image in detail and be consistent across all the images in the story for style. When you describe an image, make sure to mention that it should be a colorful, bright wide-landscape drawing suitable for technology-forward optimistic graphic-novel."},{"location":"stories/yann-lecun/#prologue-the-dreamer","title":"Prologue: The Dreamer","text":"Show Image Prompt Image 1: A colorful, bright wide-landscape drawing showing a young Yann LeCun as a teenager in France, sitting in a library surrounded by dusty books on mathematics and computing. The scene should be split between the physical reality showing him studying analog electronics and computing manuals, and a dreamy overlay showing his imagination of neural networks as glowing interconnected nodes floating above his head. The style should be vibrant and optimistic, with warm lighting streaming through library windows.  <p>In the early 1970s, while most teenagers dreamed of rock concerts and fast cars, young Yann LeCun spent his evenings in the local library in suburban Paris, devouring books on mathematics, computer science, and the emerging field of artificial intelligence. His friends thought he was eccentric \u2013 who dreams of teaching machines to think? But Yann's vision was clear: machines could learn like humans do, through observation and experience.</p>"},{"location":"stories/yann-lecun/#chapter-1-bell-labs-the-spark-of-innovation","title":"Chapter 1: Bell Labs: The Spark of Innovation","text":"Show Image Prompt Please create a new version of [this image](./holmdell-1980.jpeg) using a drawing that might appear in a colorful bright graphic novel.   <p>In 1988, LeCun joined the legendary AT&amp;T Bell Laboratories in Holmdel New Jersey were over 6,000 engineers and researchers did some of the most groundbreaking research in computer science.</p> <p></p> Show Image Prompt Image 2: Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A tech-optimistic graphic novel panel showing LeCun as a young researcher at AT&amp;T Bell Labs in 1988, working late at night surrounded by early computers and neural network diagrams on whiteboards. The scene should depict him animated and excited, gesturing toward holographic representations of digits floating above a primitive neural network diagram. The setting should have the warm orange glow of desk lamps and the blue light of computer monitors, creating an atmosphere of discovery.  <p>Holmdel was a place where innovation flowed like electricity through the halls. While others worked on traditional software, LeCun's office became a laboratory of the future. His colleagues often found him staring intently at a screen filled with handwritten digits, muttering about \"convolutional filters\" and \"local receptive fields.\" </p> <p>\"Why are you trying to reinvent image recognition?\" his skeptical colleagues would ask. \"Rule-based systems work just fine for reading zip codes.\"</p> <p>But LeCun had a vision that others couldn't yet see.</p>"},{"location":"stories/yann-lecun/#chapter-2-the-convolutional-revolution","title":"Chapter 2: The Convolutional Revolution","text":"Show Image Prompt Image 3:  Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A dynamic wide-landscape illustration showing the inner workings of a CNN processing handwritten digits. The scene should be depicted as an ethereal journey through multiple layers of convolution, showing the transition from raw pixels to abstract features. Use flowing, interconnected neural pathways with bright colors \u2013 blues for initial features, transitioning to greens for edges, yellows for shapes, and reds for final classification. The style should be both technical and artistic, making neural network concepts visually beautiful.  <p>Working late into countless nights, LeCun developed something revolutionary: convolutional neural networks (CNNs). While traditional neural networks struggled with images, treating each pixel independently, LeCun's CNNs understood that images had structure \u2013 edges, corners, shapes that mattered.</p> <p>His breakthrough came when his CNN successfully read handwritten digits on checks. The system learned to recognize numbers the way humans do \u2013 by understanding patterns and structures, not by memorizing every possible variation. AT&amp;T saved millions of dollars with this technology, but LeCun knew this was just the beginning.</p> <p></p> Show Image Prompt Image 4:  Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.   A triumphant scene in a bank processing center, split between the mundane reality of workers manually sorting checks and the futuristic overlay of LeCun's CNN system automatically reading and processing thousands of checks with glowing accuracy indicators. The style should contrast the gray, tedious manual work with the vibrant, efficient automated system powered by neural networks."},{"location":"stories/yann-lecun/#chapter-3-the-data-science-pioneer","title":"Chapter 3: The Data Science Pioneer","text":"Show Image Prompt Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.   Image 5: A colorful wide-landscape showing the inauguration of the NYU Center for Data Science in 2012. The scene should depict LeCun on stage, but instead of a traditional podium, he's surrounded by floating holographic data visualizations, neural networks, and equations. In the audience, show a mix of excited students and skeptical faculty members, with some thinking \"Data Science? That's not a real field!\" The setting should feel like a tech startup meets academic institution, with modern architecture and vibrant colors.  <p>By 2012, LeCun was ready for his next challenge. When offered a position at NYU, he didn't just join \u2013 he created something entirely new: the Center for Data Science. Many academics scoffed. \"Data Science? That's just statistics with a fancy name!\"</p> <p>But LeCun saw the future clearly. Data was becoming the world's most valuable resource, and the techniques he'd been developing could unlock its secrets. Under his leadership, the center became a magnet for brilliant minds from computer science, statistics, and engineering. Together, they pioneered the field that would soon take the world by storm.</p>"},{"location":"stories/yann-lecun/#chapter-4-building-bridges","title":"Chapter 4: Building Bridges","text":"Show Image Prompt Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.   Image 6: A conference room scene showing the first International Conference on Learning Representations (ICLR) in 2013. The panel should show LeCun and Yoshua Bengio planting seeds that grow into a massive tree of knowledge, with branches reaching out to connect researchers worldwide. Each connection should be represented by glowing lines forming a global network of innovation. The style should be aspirational and forward-thinking, with a global map in the background showing research nodes lighting up across continents.  <p>In 2013, LeCun and his longtime collaborator Yoshua Bengio faced another challenge: the field of machine learning was fragmented, with researchers working in isolation. They founded the International Conference on Learning Representations (ICLR), creating a space where ideas could flow freely.</p> <p>\"We need to build bridges, not walls,\" LeCun declared at the first conference. His vision was simple but powerful: share knowledge openly, challenge each other's ideas, and accelerate progress for everyone.</p>"},{"location":"stories/yann-lecun/#chapter-5-the-turing-triumph","title":"Chapter 5: The Turing Triumph","text":"Show Image Prompt Image 7: Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A spectacular wide-landscape showing the 2019 Turing Award ceremony with LeCun, Bengio, and Hinton standing together. Instead of just receiving medals, they should be depicted as knights of the digital realm, with data streams and neural networks forming crowns above their heads. The scene should be celebratory with confetti, but also symbolic \u2013 showing how their work has literally reshaped the world, with elements of their innovations (CNNs, deep learning, AI applications) transforming the environment around them.  <p>March 2019 brought the ultimate recognition: the Turing Award, computing's highest honor. LeCun shared this prestigious award with Yoshua Bengio and Geoffrey Hinton \u2013 three pioneers who had persevered through decades of skepticism to revolutionize artificial intelligence.</p> <p>At the ceremony, LeCun spoke not just about past achievements, but about future challenges. \"This is not the end,\" he declared. \"This is just the beginning of our understanding of intelligence.\"</p>"},{"location":"stories/yann-lecun/#chapter-6-the-agi-skeptic","title":"Chapter 6: The AGI Skeptic","text":"Show Image Prompt Image 8: Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.   A thought-provoking wide-landscape showing LeCun in his office, surrounded by whiteboards filled with diagrams. On one side, show simplified representations of LLMs (depicted as pattern-matching machines), and on the other side, show his vision of world models as complex, interconnected systems. The scene should include holographic projections of physical simulations, cause-and-effect relationships, and reasoning engines. The contrast should be clear but non-judgmental, emphasizing the complementary nature of different AI approaches.  <p>While the world celebrated the rise of large language models (LLMs) like ChatGPT, LeCun remained thoughtfully skeptical. \"Language models are impressive, but they're not enough for true intelligence,\" he would explain to packed auditoriums.</p> <p>His vision went deeper: machines needed to understand the world, not just predict text. They needed world models \u2013 internal representations of how things work, what causes what, and how to reason about unseen situations. This wasn't criticism for its own sake; this was the perspective of someone who had seen the field evolve and knew there were greater heights to reach.</p> <p></p> Show Image Prompt Image 9:  Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A visionary scene showing LeCun's concept of future AI systems. The panel should illustrate a split reality: above, current AI systems performing specific tasks (language, image recognition, etc.), and below, an integrated AI system with a comprehensive world model. This lower level should be depicted as a sophisticated machine understanding the physical world, social dynamics, causal relationships, and abstract reasoning \u2013 all connected in a harmonious, glowing network of understanding.  <p> Yann's vision is an AI system that mimics regions of the human brain.  At the center of this is models of the real world.  LLMs are good models of language, but they are not precise models of the world.</p>"},{"location":"stories/yann-lecun/#epilogue-the-continuing-quest","title":"Epilogue: The Continuing Quest","text":"Show Image Prompt Image 10:  Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A forward-looking wide-landscape that serves as the story's finale. Show LeCun as an elder statesman of AI, but still actively working and mentoring young researchers. The scene should be set in a futuristic lab where his influence is visible everywhere \u2013 from CNNs processing visual data to young scientists working on world models and next-generation AI. The atmosphere should be optimistic and inclusive, showing a diverse group of researchers continuing his legacy of challenging assumptions and pushing boundaries.  <p>Today, Yann LeCun continues his quest for truly intelligent machines. His journey from a curious teenager in Paris to a pioneering force in artificial intelligence shows that the greatest obstacles to progress are often our own preconceptions. By combining deep technical understanding with visionary leadership, he didn't just overcome challenges \u2013 he redefined what was possible.</p> <p>As he likes to say, \"The best way to predict the future is to create it.\" And for Yann LeCun, the future of artificial intelligence is still being written.</p> <p></p> Show Image Prompt Image 11:  Please generate a new drawing.  It is a wide-landscape drawing that might appear in a graphic novel.  A symbolic closing panel showing hands passing a torch between generations of AI researchers. In the background, the evolution of neural networks can be seen as a spiral timeline, from simple perceptrons to modern CNNs to future world models. The torch itself should be rendered as a glowing neural network, symbolizing the continuous flow of knowledge and innovation. The style should be hopeful and inspiring, suggesting that the story continues with each new generation of researchers."},{"location":"stories/yann-lecun/#references","title":"References","text":"<p>Here are the references reformatted:</p> <ol> <li>Yann LeCun Personal Website</li> <li>Gradient-based learning applied to document recognition - 1998 - Proceedings of the IEEE - LeCun's seminal CNN paper describing implementation at AT&amp;T Bell Labs</li> <li>MNIST Database of Handwritten Digits - 2010 (Updated) - Online Database - Original dataset created from Bell Labs work on postal code recognition</li> <li>Handwritten Digit Recognition with a Back-Propagation Network - 1990 - Advances in Neural Information Processing Systems - Early AT&amp;T Bell Labs application work</li> <li>ACM Turing Award Winners - 2019 - ACM Official Page - Official announcement of 2018 Turing Award to LeCun, Bengio, and Hinton</li> <li>NYU Center for Data Science Launch - 2012 - NYU Official Page - Founding of center with LeCun as inaugural director</li> <li>ICLR Conference History - 2013 - ICLR Official Website - Co-founded by LeCun and Bengio as premier ML conference</li> <li>LeCun's NYU Profile - Current - NYU CS Department - Official position at NYU and CV</li> <li>LeCun on AI and World Models - 2022 - MIT Technology Review - Recent interview on LLM limitations and AGI</li> <li>Facebook AI Research Appointment - 2013 - Meta Research Blog - Announcement of LeCun as FAIR director at Meta</li> <li>LeCun at Bell Labs Research - 1988-2003 - Bell Labs Archives - Documentation of LeCun's tenure and achievements at AT&amp;T Bell Labs</li> </ol>"}]}